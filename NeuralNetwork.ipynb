{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d208cb-8d4f-4f02-b840-59629a7918bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      " [[0.56496031 0.73607334 0.59274022 ... 0.31940835 0.4644783  0.28763054]\n",
      " [0.97027829 0.59423112 0.77117653 ... 0.81909783 0.17422815 0.55832177]\n",
      " [0.81641632 0.39593447 0.93674751 ... 0.19642156 0.33796344 0.30454901]\n",
      " ...\n",
      " [0.35616825 0.24477677 0.73196159 ... 0.81807558 0.07418167 0.86345524]\n",
      " [0.98693668 0.95669402 0.69009518 ... 0.74846349 0.99426307 0.16303189]\n",
      " [0.99524877 0.51538237 0.93194001 ... 0.1776084  0.40848212 0.81305817]]\n",
      "\n",
      "Actual Output: \n",
      " [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "\n",
      "Predicted Output: \n",
      " [[0.21222122]\n",
      " [0.1517028 ]\n",
      " [0.13590728]\n",
      " [0.14019269]\n",
      " [0.17823145]\n",
      " [0.13279531]\n",
      " [0.13122908]\n",
      " [0.18847043]\n",
      " [0.23193538]\n",
      " [0.15389265]\n",
      " [0.14477208]\n",
      " [0.09842617]\n",
      " [0.12701703]\n",
      " [0.16208482]\n",
      " [0.10076828]\n",
      " [0.18859068]\n",
      " [0.1450191 ]\n",
      " [0.14384588]\n",
      " [0.15425507]\n",
      " [0.107831  ]\n",
      " [0.17265873]\n",
      " [0.10116504]\n",
      " [0.30705455]\n",
      " [0.15894634]\n",
      " [0.17913859]\n",
      " [0.11164936]\n",
      " [0.13732743]\n",
      " [0.12804668]\n",
      " [0.14965659]\n",
      " [0.20200485]\n",
      " [0.14017282]\n",
      " [0.15069048]\n",
      " [0.15648565]\n",
      " [0.36183259]\n",
      " [0.23033417]\n",
      " [0.12516085]\n",
      " [0.26036482]\n",
      " [0.10073117]\n",
      " [0.14302739]\n",
      " [0.16522811]\n",
      " [0.23603053]\n",
      " [0.20872644]\n",
      " [0.10432143]\n",
      " [0.13483736]\n",
      " [0.11143938]\n",
      " [0.11317768]\n",
      " [0.2020262 ]\n",
      " [0.18847461]\n",
      " [0.17313507]\n",
      " [0.16184741]\n",
      " [0.16915918]\n",
      " [0.18212522]\n",
      " [0.11910239]\n",
      " [0.1206147 ]\n",
      " [0.14639991]\n",
      " [0.2680309 ]\n",
      " [0.22961993]\n",
      " [0.10342331]\n",
      " [0.12005753]\n",
      " [0.11167408]\n",
      " [0.21381692]\n",
      " [0.1093658 ]\n",
      " [0.14065952]\n",
      " [0.12790622]\n",
      " [0.11596352]\n",
      " [0.15847395]\n",
      " [0.1092727 ]\n",
      " [0.15896934]\n",
      " [0.1215608 ]\n",
      " [0.20545622]\n",
      " [0.11007275]\n",
      " [0.12898155]\n",
      " [0.11965312]\n",
      " [0.11965318]\n",
      " [0.1694395 ]\n",
      " [0.15751124]\n",
      " [0.14294671]\n",
      " [0.12696789]\n",
      " [0.21961146]\n",
      " [0.11457141]\n",
      " [0.11539721]\n",
      " [0.20945226]\n",
      " [0.11965341]\n",
      " [0.12085759]\n",
      " [0.12066909]\n",
      " [0.30701935]\n",
      " [0.10245243]\n",
      " [0.10645409]\n",
      " [0.20721599]\n",
      " [0.14474347]\n",
      " [0.15760215]\n",
      " [0.16004759]\n",
      " [0.11972688]\n",
      " [0.14205375]\n",
      " [0.15876871]\n",
      " [0.14217656]\n",
      " [0.1387872 ]\n",
      " [0.12983855]\n",
      " [0.17342969]\n",
      " [0.13294622]\n",
      " [0.34399084]\n",
      " [0.13154594]\n",
      " [0.11498487]\n",
      " [0.13664113]\n",
      " [0.1065985 ]\n",
      " [0.10913848]\n",
      " [0.20626357]\n",
      " [0.14515856]\n",
      " [0.16879937]\n",
      " [0.13702234]\n",
      " [0.22173289]\n",
      " [0.14601131]\n",
      " [0.33980111]\n",
      " [0.1894379 ]\n",
      " [0.16974472]\n",
      " [0.12714304]\n",
      " [0.10725385]\n",
      " [0.14425441]\n",
      " [0.16183579]\n",
      " [0.13911842]\n",
      " [0.20704462]\n",
      " [0.143149  ]\n",
      " [0.1826494 ]\n",
      " [0.12374273]\n",
      " [0.27620592]\n",
      " [0.13617468]\n",
      " [0.1427186 ]\n",
      " [0.11086915]\n",
      " [0.25583245]\n",
      " [0.0971596 ]\n",
      " [0.14750283]\n",
      " [0.17004217]\n",
      " [0.15843242]\n",
      " [0.12288901]\n",
      " [0.09925446]\n",
      " [0.16623264]\n",
      " [0.14175064]\n",
      " [0.15835499]\n",
      " [0.13203906]\n",
      " [0.18819959]\n",
      " [0.13654256]\n",
      " [0.18528988]\n",
      " [0.17650975]\n",
      " [0.17480588]\n",
      " [0.14972541]\n",
      " [0.23234765]\n",
      " [0.12118175]\n",
      " [0.13507636]\n",
      " [0.14895101]\n",
      " [0.12732893]\n",
      " [0.14553759]\n",
      " [0.1948828 ]\n",
      " [0.17129396]\n",
      " [0.13633285]\n",
      " [0.12832823]\n",
      " [0.11628825]\n",
      " [0.23216989]\n",
      " [0.1547608 ]\n",
      " [0.16291042]\n",
      " [0.12687481]\n",
      " [0.12648151]\n",
      " [0.16292576]\n",
      " [0.10770404]\n",
      " [0.18179463]\n",
      " [0.14171244]\n",
      " [0.10523594]\n",
      " [0.16371669]\n",
      " [0.17347508]\n",
      " [0.1599329 ]\n",
      " [0.14011859]\n",
      " [0.17585522]\n",
      " [0.11520521]\n",
      " [0.2488275 ]\n",
      " [0.11100595]\n",
      " [0.1813495 ]\n",
      " [0.15812234]\n",
      " [0.12901714]\n",
      " [0.15585362]\n",
      " [0.25674097]\n",
      " [0.11189161]\n",
      " [0.1430409 ]\n",
      " [0.09780995]\n",
      " [0.09922808]\n",
      " [0.10000919]\n",
      " [0.29686907]\n",
      " [0.12710909]\n",
      " [0.1220472 ]\n",
      " [0.28954987]\n",
      " [0.18625242]\n",
      " [0.14162045]\n",
      " [0.21600199]\n",
      " [0.12700613]\n",
      " [0.16562845]\n",
      " [0.14965112]\n",
      " [0.09261988]\n",
      " [0.12616687]\n",
      " [0.11942151]\n",
      " [0.12931138]\n",
      " [0.09504399]\n",
      " [0.10228823]\n",
      " [0.17796175]\n",
      " [0.18167237]\n",
      " [0.17095753]\n",
      " [0.14218591]\n",
      " [0.21464247]\n",
      " [0.26675415]\n",
      " [0.16783059]\n",
      " [0.27868633]\n",
      " [0.21496443]\n",
      " [0.17646463]\n",
      " [0.14279927]\n",
      " [0.13670893]\n",
      " [0.09174654]\n",
      " [0.14647835]\n",
      " [0.11401758]\n",
      " [0.14379977]\n",
      " [0.25384235]\n",
      " [0.18591123]\n",
      " [0.09372919]\n",
      " [0.12644282]\n",
      " [0.12713441]\n",
      " [0.12857116]\n",
      " [0.11398356]\n",
      " [0.13036483]\n",
      " [0.12866554]\n",
      " [0.13443231]\n",
      " [0.14912086]\n",
      " [0.181216  ]\n",
      " [0.14795494]\n",
      " [0.20147686]\n",
      " [0.11796418]\n",
      " [0.13777861]\n",
      " [0.13581758]\n",
      " [0.39902254]\n",
      " [0.34925735]\n",
      " [0.25123195]\n",
      " [0.11751086]\n",
      " [0.14492154]\n",
      " [0.14262742]\n",
      " [0.12658566]\n",
      " [0.14578115]\n",
      " [0.10462668]\n",
      " [0.14486902]\n",
      " [0.12959053]\n",
      " [0.15007877]\n",
      " [0.1301714 ]\n",
      " [0.13787347]\n",
      " [0.14671267]\n",
      " [0.12063524]\n",
      " [0.17850849]\n",
      " [0.12368053]\n",
      " [0.25957587]\n",
      " [0.12027748]\n",
      " [0.28067941]\n",
      " [0.15934562]\n",
      " [0.13717017]\n",
      " [0.125741  ]\n",
      " [0.13480938]\n",
      " [0.13292685]\n",
      " [0.11675896]\n",
      " [0.11799815]\n",
      " [0.11193044]\n",
      " [0.12465836]\n",
      " [0.11296754]\n",
      " [0.11096649]\n",
      " [0.1294579 ]\n",
      " [0.17345139]\n",
      " [0.14435202]\n",
      " [0.11376648]\n",
      " [0.34201851]\n",
      " [0.15975518]\n",
      " [0.13527144]\n",
      " [0.09492572]\n",
      " [0.17548262]\n",
      " [0.12001804]\n",
      " [0.11421317]\n",
      " [0.11472156]\n",
      " [0.14650588]\n",
      " [0.12965614]\n",
      " [0.13015611]\n",
      " [0.17182674]\n",
      " [0.12090028]\n",
      " [0.15297381]\n",
      " [0.26778201]\n",
      " [0.11140648]\n",
      " [0.15847925]\n",
      " [0.1278557 ]\n",
      " [0.1142071 ]\n",
      " [0.16063117]\n",
      " [0.16745972]\n",
      " [0.13979808]\n",
      " [0.2326038 ]\n",
      " [0.15153607]\n",
      " [0.14182597]\n",
      " [0.13320973]\n",
      " [0.18663169]\n",
      " [0.25256289]\n",
      " [0.17205472]\n",
      " [0.14190274]\n",
      " [0.1475391 ]\n",
      " [0.14026703]\n",
      " [0.12100215]\n",
      " [0.23482805]\n",
      " [0.21694523]\n",
      " [0.12403864]\n",
      " [0.1380652 ]\n",
      " [0.15926179]\n",
      " [0.21031461]\n",
      " [0.11072879]\n",
      " [0.1076924 ]\n",
      " [0.12591965]\n",
      " [0.12664435]\n",
      " [0.1981323 ]\n",
      " [0.24845892]\n",
      " [0.20515101]\n",
      " [0.09488849]\n",
      " [0.12239082]\n",
      " [0.26099679]\n",
      " [0.20907685]\n",
      " [0.16308296]\n",
      " [0.13724402]\n",
      " [0.12593786]\n",
      " [0.2301207 ]\n",
      " [0.13392859]\n",
      " [0.16576791]\n",
      " [0.16531647]\n",
      " [0.17037037]\n",
      " [0.14573972]\n",
      " [0.11556153]\n",
      " [0.23006495]\n",
      " [0.09192005]\n",
      " [0.10789088]\n",
      " [0.10650621]\n",
      " [0.1285111 ]\n",
      " [0.15832043]\n",
      " [0.11324048]\n",
      " [0.17273485]\n",
      " [0.21916638]\n",
      " [0.17122727]\n",
      " [0.13878114]\n",
      " [0.19547496]\n",
      " [0.25126217]\n",
      " [0.13435133]\n",
      " [0.15534327]\n",
      " [0.10210549]\n",
      " [0.17880258]\n",
      " [0.18030097]\n",
      " [0.19601995]\n",
      " [0.1208292 ]\n",
      " [0.12520293]\n",
      " [0.14273992]\n",
      " [0.10316795]\n",
      " [0.10899083]\n",
      " [0.13570123]\n",
      " [0.10189774]\n",
      " [0.14051388]\n",
      " [0.22986148]\n",
      " [0.21266873]\n",
      " [0.10657354]\n",
      " [0.09045853]\n",
      " [0.11395049]\n",
      " [0.1566095 ]\n",
      " [0.13188046]\n",
      " [0.12011296]\n",
      " [0.11752699]\n",
      " [0.16497791]\n",
      " [0.13304486]\n",
      " [0.10377341]\n",
      " [0.21482801]\n",
      " [0.12690645]\n",
      " [0.14476134]\n",
      " [0.22337094]\n",
      " [0.23747997]\n",
      " [0.10371406]\n",
      " [0.08585443]\n",
      " [0.11927636]\n",
      " [0.13109964]\n",
      " [0.14962389]\n",
      " [0.13334648]\n",
      " [0.11839537]\n",
      " [0.24950511]\n",
      " [0.12979727]\n",
      " [0.09641781]\n",
      " [0.15257182]\n",
      " [0.14393859]\n",
      " [0.10494579]\n",
      " [0.16582481]\n",
      " [0.1283801 ]\n",
      " [0.10056235]\n",
      " [0.09535924]\n",
      " [0.15884786]\n",
      " [0.30321687]\n",
      " [0.16725268]\n",
      " [0.13030443]\n",
      " [0.16162457]\n",
      " [0.1017121 ]\n",
      " [0.11313456]\n",
      " [0.20528712]\n",
      " [0.09653541]\n",
      " [0.09683022]\n",
      " [0.30192272]\n",
      " [0.10259088]\n",
      " [0.21811479]\n",
      " [0.14735999]\n",
      " [0.14684177]\n",
      " [0.21724328]\n",
      " [0.12366849]\n",
      " [0.1545729 ]\n",
      " [0.39133847]\n",
      " [0.18686992]\n",
      " [0.20036454]\n",
      " [0.11911766]\n",
      " [0.13454528]\n",
      " [0.16234889]\n",
      " [0.13589707]\n",
      " [0.1030693 ]\n",
      " [0.19921905]\n",
      " [0.12865495]\n",
      " [0.15004174]\n",
      " [0.11782577]\n",
      " [0.26372858]\n",
      " [0.11339889]\n",
      " [0.14740514]\n",
      " [0.20740829]\n",
      " [0.16602215]\n",
      " [0.09235195]\n",
      " [0.1730246 ]\n",
      " [0.20904975]\n",
      " [0.13790382]\n",
      " [0.12159148]\n",
      " [0.1058895 ]\n",
      " [0.17186049]\n",
      " [0.14108306]\n",
      " [0.11831809]\n",
      " [0.14174536]\n",
      " [0.12081483]\n",
      " [0.11377794]\n",
      " [0.21027681]\n",
      " [0.17949957]\n",
      " [0.35935984]\n",
      " [0.14231271]\n",
      " [0.14080287]\n",
      " [0.13010348]\n",
      " [0.11675523]\n",
      " [0.12624817]\n",
      " [0.09417143]\n",
      " [0.1631514 ]\n",
      " [0.14648202]\n",
      " [0.21125887]\n",
      " [0.13525139]\n",
      " [0.17888204]\n",
      " [0.15225676]\n",
      " [0.09658898]\n",
      " [0.15030841]\n",
      " [0.16390866]\n",
      " [0.10087961]\n",
      " [0.12865793]\n",
      " [0.12929569]\n",
      " [0.10101712]\n",
      " [0.22279169]\n",
      " [0.1635293 ]\n",
      " [0.17262349]\n",
      " [0.12778872]\n",
      " [0.11913156]\n",
      " [0.1083772 ]\n",
      " [0.13279989]\n",
      " [0.18232867]\n",
      " [0.12051232]\n",
      " [0.15887478]\n",
      " [0.14711825]\n",
      " [0.16570177]\n",
      " [0.1394026 ]\n",
      " [0.14466866]\n",
      " [0.129897  ]\n",
      " [0.12983779]\n",
      " [0.15610727]\n",
      " [0.13057912]\n",
      " [0.12624852]\n",
      " [0.09830361]\n",
      " [0.15093214]\n",
      " [0.13616923]\n",
      " [0.16097813]\n",
      " [0.11312237]\n",
      " [0.17140481]\n",
      " [0.14533427]\n",
      " [0.13023149]\n",
      " [0.11842532]\n",
      " [0.22505614]\n",
      " [0.14333472]\n",
      " [0.10465653]\n",
      " [0.11786744]\n",
      " [0.23305436]\n",
      " [0.14112524]\n",
      " [0.17637787]\n",
      " [0.12795732]\n",
      " [0.1147492 ]\n",
      " [0.14835552]\n",
      " [0.28465645]\n",
      " [0.14481236]\n",
      " [0.13971188]]\n",
      "\n",
      "Loss: \n",
      " 0.12136098950033136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv(\"student_dataset.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df.drop(columns=[\"Final_Score\"]).values  # All columns except target\n",
    "y = df[\"Final_Score\"].values.reshape(-1, 1)  # Target column\n",
    "\n",
    "# Normalize features\n",
    "X = X / np.amax(X, axis=0)\n",
    "y = y / 100  # Normalize target\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize = X.shape[1]\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 8  # Increased hidden layer size for better learning\n",
    "        \n",
    "        # Weights\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)  # Weight matrix from input to hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # Weight matrix from hidden to output layer\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.W1)        # Dot product of input and first set of weights\n",
    "        self.z2 = self.sigmoid(self.z)     # Activation function\n",
    "        self.z3 = np.dot(self.z2, self.W2) # Dot product of hidden layer and second set of weights\n",
    "        o = self.sigmoid(self.z3)          # Final activation\n",
    "        return o\n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)  # Derivative of sigmoid\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o  # Error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)  # Applying derivative of sigmoid to output error\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)  # Error in hidden layer\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)  # Applying derivative of sigmoid\n",
    "        \n",
    "        self.W1 += X.T.dot(self.z2_delta)  # Adjust input -> hidden weights\n",
    "        self.W2 += self.z2.T.dot(self.o_delta)  # Adjust hidden -> output weights\n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "\n",
    "NN = Neural_Network()\n",
    "print(\"\\nInput: \\n\", X)\n",
    "print(\"\\nActual Output: \\n\", y)\n",
    "print(\"\\nPredicted Output: \\n\", NN.forward(X))\n",
    "print(\"\\nLoss: \\n\", np.mean(np.square(y - NN.forward(X))))  # Mean squared loss\n",
    "\n",
    "NN.train(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faea857e-38f3-4fdb-bb31-644bdccc984a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, o\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m W1, W2, predictions \u001b[38;5;241m=\u001b[39m train(X, y)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, X)\n",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, hidden_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     61\u001b[0m     z, z2, z3, o \u001b[38;5;241m=\u001b[39m forward_pass(X, W1, W2)\n\u001b[1;32m---> 62\u001b[0m     W1, W2 \u001b[38;5;241m=\u001b[39m backward_pass(X, y, W1, W2, z, z2, z3, o, learning_rate)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, o\n",
      "Cell \u001b[1;32mIn[2], line 47\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(X, y, W1, W2, z, z2, z3, o, learning_rate)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1)):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1[i])):\n\u001b[1;32m---> 47\u001b[0m         W1[i][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(X[k][i] \u001b[38;5;241m*\u001b[39m z2_delta[k][j] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2)):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2[i])):\n",
      "Cell \u001b[1;32mIn[2], line 47\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1)):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1[i])):\n\u001b[1;32m---> 47\u001b[0m         W1[i][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(X[k][i] \u001b[38;5;241m*\u001b[39m z2_delta[k][j] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2)):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2[i])):\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Load dataset manually\n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = list(reader)\n",
    "    return [[float(value) for value in row] for row in data[1:]]  # Skip header\n",
    "\n",
    "data = load_csv(\"student_dataset.csv\")\n",
    "X = [row[:-1] for row in data]  # Features\n",
    "y = [[row[-1] / 100] for row in data]  # Normalize target\n",
    "\n",
    "# Initialize weights\n",
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    W1 = [[random.uniform(-1, 1) for _ in range(hidden_size)] for _ in range(input_size)]\n",
    "    W2 = [[random.uniform(-1, 1) for _ in range(output_size)] for _ in range(hidden_size)]\n",
    "    return W1, W2\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Forward pass\n",
    "def forward_pass(X, W1, W2):\n",
    "    z = [[sum(i * w for i, w in zip(row, col)) for col in zip(*W1)] for row in X]\n",
    "    z2 = [[sigmoid(val) for val in row] for row in z]\n",
    "    z3 = [[sum(i * w for i, w in zip(row, col)) for col in zip(*W2)] for row in z2]\n",
    "    o = [[sigmoid(val) for val in row] for row in z3]\n",
    "    return z, z2, z3, o\n",
    "\n",
    "# Backpropagation\n",
    "def backward_pass(X, y, W1, W2, z, z2, z3, o, learning_rate=0.01):\n",
    "    o_error = [[yi - oi for yi, oi in zip(y_row, o_row)] for y_row, o_row in zip(y, o)]\n",
    "    o_delta = [[err * sigmoid_derivative(oi) for err, oi in zip(err_row, o_row)] for err_row, o_row in zip(o_error, o)]\n",
    "    \n",
    "    z2_error = [[sum(d * w for d, w in zip(delta_row, col)) for col in zip(*W2)] for delta_row in o_delta]\n",
    "    z2_delta = [[err * sigmoid_derivative(zi) for err, zi in zip(err_row, z2_row)] for err_row, z2_row in zip(z2_error, z2)]\n",
    "    \n",
    "    for i in range(len(W1)):\n",
    "        for j in range(len(W1[i])):\n",
    "            W1[i][j] += learning_rate * sum(X[k][i] * z2_delta[k][j] for k in range(len(X)))\n",
    "    \n",
    "    for i in range(len(W2)):\n",
    "        for j in range(len(W2[i])):\n",
    "            W2[i][j] += learning_rate * sum(z2[k][i] * o_delta[k][j] for k in range(len(z2)))\n",
    "    \n",
    "    return W1, W2\n",
    "\n",
    "# Training function\n",
    "def train(X, y, hidden_size=8, epochs=100, learning_rate=0.01):\n",
    "    input_size, output_size = len(X[0]), 1\n",
    "    W1, W2 = initialize_weights(input_size, hidden_size, output_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        z, z2, z3, o = forward_pass(X, W1, W2)\n",
    "        W1, W2 = backward_pass(X, y, W1, W2, z, z2, z3, o, learning_rate)\n",
    "    \n",
    "    return W1, W2, o\n",
    "\n",
    "# Train the model\n",
    "W1, W2, predictions = train(X, y)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nInput: \\n\", X)\n",
    "print(\"\\nActual Output: \\n\", y)\n",
    "print(\"\\nPredicted Output: \\n\", predictions)\n",
    "print(\"\\nLoss: \\n\", sum(sum((yi - oi) ** 2 for yi, oi in zip(y_row, o_row)) for y_row, o_row in zip(y, predictions)) / len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2187d41b-b724-4b4f-9b46-2ee70012f745",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, o\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m W1, W2, predictions \u001b[38;5;241m=\u001b[39m train(X, y)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, X)\n",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, hidden_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     61\u001b[0m     z, z2, z3, o \u001b[38;5;241m=\u001b[39m forward_pass(X, W1, W2)\n\u001b[1;32m---> 62\u001b[0m     W1, W2 \u001b[38;5;241m=\u001b[39m backward_pass(X, y, W1, W2, z, z2, z3, o, learning_rate)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, o\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36mbackward_pass\u001b[1;34m(X, y, W1, W2, z, z2, z3, o, learning_rate)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1)):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1[i])):\n\u001b[1;32m---> 47\u001b[0m         W1[i][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(X[k][i] \u001b[38;5;241m*\u001b[39m z2_delta[k][j] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2)):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2[i])):\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1)):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W1[i])):\n\u001b[1;32m---> 47\u001b[0m         W1[i][j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(X[k][i] \u001b[38;5;241m*\u001b[39m z2_delta[k][j] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2)):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(W2[i])):\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Load dataset manually\n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = list(reader)\n",
    "    return [[float(value) for value in row] for row in data[1:]]  # Skip header\n",
    "\n",
    "data = load_csv(\"student_dataset.csv\")\n",
    "X = [row[:-1] for row in data]  # Features\n",
    "y = [[row[-1] / 100] for row in data]  # Normalize target\n",
    "\n",
    "# Initialize weights\n",
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    W1 = [[random.uniform(-1, 1) for _ in range(hidden_size)] for _ in range(input_size)]\n",
    "    W2 = [[random.uniform(-1, 1) for _ in range(output_size)] for _ in range(hidden_size)]\n",
    "    return W1, W2\n",
    "\n",
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Forward pass\n",
    "def forward_pass(X, W1, W2):\n",
    "    z = [[sum(i * w for i, w in zip(row, col)) for col in zip(*W1)] for row in X]\n",
    "    z2 = [[sigmoid(val) for val in row] for row in z]\n",
    "    z3 = [[sum(i * w for i, w in zip(row, col)) for col in zip(*W2)] for row in z2]\n",
    "    o = [[sigmoid(val) for val in row] for row in z3]\n",
    "    return z, z2, z3, o\n",
    "\n",
    "# Backpropagation\n",
    "def backward_pass(X, y, W1, W2, z, z2, z3, o, learning_rate=0.01):\n",
    "    o_error = [[yi - oi for yi, oi in zip(y_row, o_row)] for y_row, o_row in zip(y, o)]\n",
    "    o_delta = [[err * sigmoid_derivative(oi) for err, oi in zip(err_row, o_row)] for err_row, o_row in zip(o_error, o)]\n",
    "    \n",
    "    z2_error = [[sum(d * w for d, w in zip(delta_row, col)) for col in zip(*W2)] for delta_row in o_delta]\n",
    "    z2_delta = [[err * sigmoid_derivative(zi) for err, zi in zip(err_row, z2_row)] for err_row, z2_row in zip(z2_error, z2)]\n",
    "    \n",
    "    for i in range(len(W1)):\n",
    "        for j in range(len(W1[i])):\n",
    "            W1[i][j] += learning_rate * sum(X[k][i] * z2_delta[k][j] for k in range(len(X)))\n",
    "    \n",
    "    for i in range(len(W2)):\n",
    "        for j in range(len(W2[i])):\n",
    "            W2[i][j] += learning_rate * sum(z2[k][i] * o_delta[k][j] for k in range(len(z2)))\n",
    "    \n",
    "    return W1, W2\n",
    "\n",
    "# Training function\n",
    "def train(X, y, hidden_size=8, epochs=100, learning_rate=0.01):\n",
    "    input_size, output_size = len(X[0]), 1\n",
    "    W1, W2 = initialize_weights(input_size, hidden_size, output_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        z, z2, z3, o = forward_pass(X, W1, W2)\n",
    "        W1, W2 = backward_pass(X, y, W1, W2, z, z2, z3, o, learning_rate)\n",
    "    \n",
    "    return W1, W2, o\n",
    "\n",
    "# Train the model\n",
    "W1, W2, predictions = train(X, y)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nInput: \\n\", X)\n",
    "print(\"\\nActual Output: \\n\", y)\n",
    "print(\"\\nPredicted Output: \\n\", predictions)\n",
    "print(\"\\nLoss: \\n\", sum(sum((yi - oi) ** 2 for yi, oi in zip(y_row, o_row)) for y_row, o_row in zip(y, predictions)) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73498831-e3dd-4681-805f-04fccf418f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 2.694973452718413e-05\n",
      "Epoch 0, Loss: 2.694973452718413e-05\n",
      "Epoch 1000, Loss: 2.504571447809962e-12\n",
      "Epoch 2000, Loss: 2.4882017140148408e-12\n",
      "Epoch 3000, Loss: 2.471974271400901e-12\n",
      "Epoch 4000, Loss: 2.4558875301936063e-12\n",
      "Epoch 5000, Loss: 2.4399399224909473e-12\n",
      "Epoch 6000, Loss: 2.42412990182504e-12\n",
      "Epoch 7000, Loss: 2.408455942908207e-12\n",
      "Epoch 8000, Loss: 2.3929165412137383e-12\n",
      "Epoch 9000, Loss: 2.3775102127126853e-12\n",
      "\n",
      "Final Predicted Output:\n",
      " [[0.50000146]\n",
      " [0.49999669]\n",
      " [0.50000103]\n",
      " [0.49999809]\n",
      " [0.4999989 ]\n",
      " [0.49999918]\n",
      " [0.50000126]\n",
      " [0.49999945]\n",
      " [0.50000029]\n",
      " [0.50000098]\n",
      " [0.5000002 ]\n",
      " [0.49999846]\n",
      " [0.49999917]\n",
      " [0.50000044]\n",
      " [0.49999928]\n",
      " [0.49999808]\n",
      " [0.49999983]\n",
      " [0.50000069]\n",
      " [0.49999954]\n",
      " [0.5000009 ]\n",
      " [0.50000216]\n",
      " [0.49999613]\n",
      " [0.500002  ]\n",
      " [0.49999982]\n",
      " [0.50000111]\n",
      " [0.50000086]\n",
      " [0.50000098]\n",
      " [0.50000061]\n",
      " [0.49999878]\n",
      " [0.50000241]\n",
      " [0.50000065]\n",
      " [0.4999978 ]\n",
      " [0.50000136]\n",
      " [0.50000278]\n",
      " [0.49999975]\n",
      " [0.49999858]\n",
      " [0.49999869]\n",
      " [0.50000113]\n",
      " [0.50000269]\n",
      " [0.49999663]\n",
      " [0.49999884]\n",
      " [0.50000311]\n",
      " [0.49999931]\n",
      " [0.50000131]\n",
      " [0.50000128]\n",
      " [0.49999871]\n",
      " [0.50000206]\n",
      " [0.49999963]\n",
      " [0.50000137]\n",
      " [0.50000282]\n",
      " [0.50000041]\n",
      " [0.50000229]\n",
      " [0.4999983 ]\n",
      " [0.49999739]\n",
      " [0.49999944]\n",
      " [0.49999887]\n",
      " [0.49999983]\n",
      " [0.49999688]\n",
      " [0.49999821]\n",
      " [0.49999837]\n",
      " [0.50000193]\n",
      " [0.49999863]\n",
      " [0.5000014 ]\n",
      " [0.49999577]\n",
      " [0.49999705]\n",
      " [0.50000082]\n",
      " [0.49999971]\n",
      " [0.49999733]\n",
      " [0.50000086]\n",
      " [0.50000212]\n",
      " [0.49999951]\n",
      " [0.49999816]\n",
      " [0.4999987 ]\n",
      " [0.49999918]\n",
      " [0.5000029 ]\n",
      " [0.50000048]\n",
      " [0.50000317]\n",
      " [0.50000082]\n",
      " [0.49999897]\n",
      " [0.50000035]\n",
      " [0.5000003 ]\n",
      " [0.50000246]\n",
      " [0.49999775]\n",
      " [0.49999764]\n",
      " [0.49999911]\n",
      " [0.5000021 ]\n",
      " [0.49999965]\n",
      " [0.50000165]\n",
      " [0.50000034]\n",
      " [0.50000159]\n",
      " [0.49999983]\n",
      " [0.49999998]\n",
      " [0.50000206]\n",
      " [0.49999991]\n",
      " [0.49999955]\n",
      " [0.50000065]\n",
      " [0.49999813]\n",
      " [0.50000097]\n",
      " [0.49999894]\n",
      " [0.50000026]\n",
      " [0.49999867]\n",
      " [0.49999941]\n",
      " [0.50000038]\n",
      " [0.49999872]\n",
      " [0.49999903]\n",
      " [0.49999882]\n",
      " [0.50000369]\n",
      " [0.49999982]\n",
      " [0.50000122]\n",
      " [0.49999969]\n",
      " [0.50000078]\n",
      " [0.49999923]\n",
      " [0.50000148]\n",
      " [0.50000061]\n",
      " [0.5000029 ]\n",
      " [0.49999974]\n",
      " [0.49999901]\n",
      " [0.49999768]\n",
      " [0.49999943]\n",
      " [0.50000173]\n",
      " [0.50000002]\n",
      " [0.50000156]\n",
      " [0.49999985]\n",
      " [0.49999951]\n",
      " [0.50000185]\n",
      " [0.49999998]\n",
      " [0.50000284]\n",
      " [0.4999981 ]\n",
      " [0.49999868]\n",
      " [0.50000136]\n",
      " [0.49999931]\n",
      " [0.4999986 ]\n",
      " [0.4999976 ]\n",
      " [0.50000079]\n",
      " [0.49999649]\n",
      " [0.49999944]\n",
      " [0.49999901]\n",
      " [0.5000004 ]\n",
      " [0.49999615]\n",
      " [0.50000028]\n",
      " [0.5000007 ]\n",
      " [0.50000112]\n",
      " [0.50000018]\n",
      " [0.4999994 ]\n",
      " [0.50000129]\n",
      " [0.50000061]\n",
      " [0.5000027 ]\n",
      " [0.50000176]\n",
      " [0.49999906]\n",
      " [0.49999955]\n",
      " [0.50000207]\n",
      " [0.49999872]\n",
      " [0.50000184]\n",
      " [0.50000028]\n",
      " [0.50000034]\n",
      " [0.50000073]\n",
      " [0.50000033]\n",
      " [0.50000348]\n",
      " [0.49999913]\n",
      " [0.49999878]\n",
      " [0.49999912]\n",
      " [0.50000071]\n",
      " [0.4999974 ]\n",
      " [0.5000002 ]\n",
      " [0.50000161]\n",
      " [0.49999932]\n",
      " [0.49999945]\n",
      " [0.50000096]\n",
      " [0.49999877]\n",
      " [0.49999886]\n",
      " [0.5000019 ]\n",
      " [0.49999879]\n",
      " [0.49999946]\n",
      " [0.49999678]\n",
      " [0.5000016 ]\n",
      " [0.50000012]\n",
      " [0.49999947]\n",
      " [0.49999976]\n",
      " [0.50000133]\n",
      " [0.49999842]\n",
      " [0.49999893]\n",
      " [0.50000189]\n",
      " [0.49999994]\n",
      " [0.49999972]\n",
      " [0.50000132]\n",
      " [0.49999968]\n",
      " [0.49999951]\n",
      " [0.50000076]\n",
      " [0.50000209]\n",
      " [0.50000207]\n",
      " [0.49999948]\n",
      " [0.49999901]\n",
      " [0.50000154]\n",
      " [0.50000081]\n",
      " [0.50000221]\n",
      " [0.50000211]\n",
      " [0.50000222]\n",
      " [0.50000082]\n",
      " [0.49999964]\n",
      " [0.49999836]\n",
      " [0.50000093]\n",
      " [0.50000108]\n",
      " [0.50000034]\n",
      " [0.50000123]\n",
      " [0.50000143]\n",
      " [0.49999939]\n",
      " [0.49999934]\n",
      " [0.50000161]\n",
      " [0.50000075]\n",
      " [0.49999943]\n",
      " [0.49999824]\n",
      " [0.50000035]\n",
      " [0.50000082]\n",
      " [0.4999988 ]\n",
      " [0.49999959]\n",
      " [0.49999919]\n",
      " [0.50000012]\n",
      " [0.50000106]\n",
      " [0.49999942]\n",
      " [0.49999995]\n",
      " [0.49999706]\n",
      " [0.50000162]\n",
      " [0.50000068]\n",
      " [0.49999927]\n",
      " [0.5000028 ]\n",
      " [0.50000115]\n",
      " [0.50000289]\n",
      " [0.50000012]\n",
      " [0.5000005 ]\n",
      " [0.50000037]\n",
      " [0.49999753]\n",
      " [0.5       ]\n",
      " [0.4999992 ]\n",
      " [0.50000207]\n",
      " [0.50000028]\n",
      " [0.49999922]\n",
      " [0.50000166]\n",
      " [0.4999966 ]\n",
      " [0.49999846]\n",
      " [0.49999744]\n",
      " [0.50000035]\n",
      " [0.49999962]\n",
      " [0.50000101]\n",
      " [0.50000277]\n",
      " [0.50000119]\n",
      " [0.49999816]\n",
      " [0.50000248]\n",
      " [0.50000101]\n",
      " [0.49999794]\n",
      " [0.50000126]\n",
      " [0.49999735]\n",
      " [0.50000209]\n",
      " [0.50000187]\n",
      " [0.49999919]\n",
      " [0.50000217]\n",
      " [0.50000178]\n",
      " [0.5000009 ]\n",
      " [0.50000284]\n",
      " [0.5000015 ]\n",
      " [0.49999788]\n",
      " [0.50000183]\n",
      " [0.49999822]\n",
      " [0.50000106]\n",
      " [0.50000099]\n",
      " [0.50000249]\n",
      " [0.50000111]\n",
      " [0.49999755]\n",
      " [0.49999958]\n",
      " [0.49999923]\n",
      " [0.49999947]\n",
      " [0.49999888]\n",
      " [0.50000016]\n",
      " [0.49999839]\n",
      " [0.49999865]\n",
      " [0.49999701]\n",
      " [0.49999929]\n",
      " [0.50000101]\n",
      " [0.5000016 ]\n",
      " [0.50000152]\n",
      " [0.50000029]\n",
      " [0.50000046]\n",
      " [0.50000206]\n",
      " [0.50000001]\n",
      " [0.49999897]\n",
      " [0.49999928]\n",
      " [0.49999795]\n",
      " [0.49999936]\n",
      " [0.49999743]\n",
      " [0.50000133]\n",
      " [0.49999876]\n",
      " [0.49999782]\n",
      " [0.5000008 ]\n",
      " [0.49999952]\n",
      " [0.49999793]\n",
      " [0.50000038]\n",
      " [0.50000001]\n",
      " [0.50000125]\n",
      " [0.50000245]\n",
      " [0.499999  ]\n",
      " [0.50000202]\n",
      " [0.50000044]\n",
      " [0.49999873]\n",
      " [0.50000016]\n",
      " [0.50000031]\n",
      " [0.49999745]\n",
      " [0.50000045]\n",
      " [0.4999992 ]\n",
      " [0.50000178]\n",
      " [0.49999931]\n",
      " [0.49999753]\n",
      " [0.49999829]\n",
      " [0.49999948]\n",
      " [0.49999811]\n",
      " [0.50000235]\n",
      " [0.49999925]\n",
      " [0.50000123]\n",
      " [0.50000195]\n",
      " [0.49999958]\n",
      " [0.50000104]\n",
      " [0.49999942]\n",
      " [0.49999838]\n",
      " [0.50000008]\n",
      " [0.50000148]\n",
      " [0.50000216]\n",
      " [0.50000077]\n",
      " [0.50000008]\n",
      " [0.49999819]\n",
      " [0.49999988]\n",
      " [0.49999867]\n",
      " [0.50000031]\n",
      " [0.49999916]\n",
      " [0.50000047]\n",
      " [0.49999736]\n",
      " [0.49999896]\n",
      " [0.49999953]\n",
      " [0.49999895]\n",
      " [0.50000197]\n",
      " [0.50000298]\n",
      " [0.49999754]\n",
      " [0.49999992]\n",
      " [0.50000299]\n",
      " [0.49999899]\n",
      " [0.5000008 ]\n",
      " [0.49999856]\n",
      " [0.50000062]\n",
      " [0.50000068]\n",
      " [0.49999914]\n",
      " [0.50000234]\n",
      " [0.50000062]\n",
      " [0.50000102]\n",
      " [0.50000063]\n",
      " [0.49999988]\n",
      " [0.49999719]\n",
      " [0.49999931]\n",
      " [0.49999944]\n",
      " [0.49999808]\n",
      " [0.49999961]\n",
      " [0.50000223]\n",
      " [0.49999977]\n",
      " [0.50000047]\n",
      " [0.49999976]\n",
      " [0.49999829]\n",
      " [0.49999891]\n",
      " [0.50000249]\n",
      " [0.49999931]\n",
      " [0.49999672]\n",
      " [0.4999985 ]\n",
      " [0.50000226]\n",
      " [0.50000238]\n",
      " [0.49999907]\n",
      " [0.50000076]\n",
      " [0.49999862]\n",
      " [0.4999995 ]\n",
      " [0.49999872]\n",
      " [0.49999702]\n",
      " [0.49999625]\n",
      " [0.49999812]\n",
      " [0.5000018 ]\n",
      " [0.50000143]\n",
      " [0.50000033]\n",
      " [0.50000114]\n",
      " [0.49999748]\n",
      " [0.49999898]\n",
      " [0.50000142]\n",
      " [0.49999925]\n",
      " [0.5000008 ]\n",
      " [0.50000006]\n",
      " [0.49999643]\n",
      " [0.49999763]\n",
      " [0.49999939]\n",
      " [0.50000028]\n",
      " [0.50000327]\n",
      " [0.50000032]\n",
      " [0.50000059]\n",
      " [0.50000036]\n",
      " [0.49999782]\n",
      " [0.50000069]\n",
      " [0.50000056]\n",
      " [0.49999889]\n",
      " [0.50000063]\n",
      " [0.50000203]\n",
      " [0.50000182]\n",
      " [0.50000124]\n",
      " [0.49999919]\n",
      " [0.49999925]\n",
      " [0.5000012 ]\n",
      " [0.49999701]\n",
      " [0.49999874]\n",
      " [0.50000057]\n",
      " [0.50000114]\n",
      " [0.50000142]\n",
      " [0.50000275]\n",
      " [0.4999974 ]\n",
      " [0.49999888]\n",
      " [0.50000078]\n",
      " [0.49999838]\n",
      " [0.50000063]\n",
      " [0.49999923]\n",
      " [0.49999881]\n",
      " [0.49999971]\n",
      " [0.49999985]\n",
      " [0.49999774]\n",
      " [0.50000064]\n",
      " [0.50000056]\n",
      " [0.49999896]\n",
      " [0.49999867]\n",
      " [0.49999745]\n",
      " [0.50000013]\n",
      " [0.50000041]\n",
      " [0.49999923]\n",
      " [0.50000209]\n",
      " [0.49999919]\n",
      " [0.50000013]\n",
      " [0.49999789]\n",
      " [0.50000253]\n",
      " [0.49999845]\n",
      " [0.50000249]\n",
      " [0.50000008]\n",
      " [0.49999908]\n",
      " [0.49999772]\n",
      " [0.50000189]\n",
      " [0.49999966]\n",
      " [0.49999939]\n",
      " [0.49999877]\n",
      " [0.4999989 ]\n",
      " [0.49999844]\n",
      " [0.50000275]\n",
      " [0.50000064]\n",
      " [0.50000147]\n",
      " [0.49999749]\n",
      " [0.50000167]\n",
      " [0.50000209]\n",
      " [0.49999854]\n",
      " [0.50000123]\n",
      " [0.49999953]\n",
      " [0.49999998]\n",
      " [0.49999882]\n",
      " [0.49999954]\n",
      " [0.4999983 ]\n",
      " [0.50000159]\n",
      " [0.49999972]\n",
      " [0.50000004]\n",
      " [0.50000249]\n",
      " [0.49999938]\n",
      " [0.50000233]\n",
      " [0.49999988]\n",
      " [0.50000158]\n",
      " [0.49999916]\n",
      " [0.49999863]\n",
      " [0.50000046]\n",
      " [0.50000039]\n",
      " [0.50000177]\n",
      " [0.50000098]\n",
      " [0.50000082]\n",
      " [0.50000071]\n",
      " [0.50000018]\n",
      " [0.49999794]\n",
      " [0.49999888]\n",
      " [0.49999868]\n",
      " [0.50000092]\n",
      " [0.49999762]\n",
      " [0.50000219]\n",
      " [0.50000094]\n",
      " [0.49999999]\n",
      " [0.49999938]\n",
      " [0.50000083]\n",
      " [0.50000043]\n",
      " [0.50000011]\n",
      " [0.50000168]\n",
      " [0.50000025]\n",
      " [0.49999897]\n",
      " [0.50000234]\n",
      " [0.50000017]\n",
      " [0.49999805]\n",
      " [0.49999866]\n",
      " [0.49999736]\n",
      " [0.49999975]\n",
      " [0.50000008]\n",
      " [0.4999991 ]\n",
      " [0.49999986]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv(\"student_dataset.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df.drop(columns=[\"Final_Score\"]).values  # All columns except target\n",
    "y = df[\"Final_Score\"].values.reshape(-1, 1)  # Target column\n",
    "\n",
    "# Normalize features\n",
    "X = X / np.amax(X, axis=0)\n",
    "y = y / 100  # Normalize target\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Weights initialization\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoid_derivative(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1)\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2)\n",
    "        self.output = self.sigmoid(self.z2)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        output_error = y - self.output  # Error in output\n",
    "        output_delta = output_error * self.sigmoid_derivative(self.output)  # Applying derivative of sigmoid\n",
    "        \n",
    "        hidden_error = output_delta.dot(self.W2.T)  # Error in hidden layer\n",
    "        hidden_delta = hidden_error * self.sigmoid_derivative(self.a1)  # Applying derivative of sigmoid\n",
    "        \n",
    "        # Weight updates\n",
    "        self.W2 += self.a1.T.dot(output_delta) * self.learning_rate\n",
    "        self.W1 += X.T.dot(hidden_delta) * self.learning_rate\n",
    "    \n",
    "    def train(self, X, y, epochs=10000):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(X, y)\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = np.mean(np.square(y - self.output))\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Initialize and train the neural network\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 8  # You can adjust this\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "NN = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)\n",
    "print(\"Initial Loss:\", np.mean(np.square(y - NN.forward(X))))\n",
    "\n",
    "NN.train(X, y)\n",
    "\n",
    "print(\"\\nFinal Predicted Output:\\n\", NN.forward(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ded8a4-7c37-4e35-9c83-af922d0d8b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 5.719681886866199e-06\n",
      "Epoch 0, Loss: 5.719681886866199e-06\n",
      "Epoch 1000, Loss: 3.5038713761829592e-12\n",
      "Epoch 2000, Loss: 3.4947379924779472e-12\n",
      "Epoch 3000, Loss: 3.485636416240578e-12\n",
      "Epoch 4000, Loss: 3.4765665179750923e-12\n",
      "Epoch 5000, Loss: 3.4675281687818863e-12\n",
      "Epoch 6000, Loss: 3.45852124040763e-12\n",
      "Epoch 7000, Loss: 3.4495456051316826e-12\n",
      "Epoch 8000, Loss: 3.4406011359036678e-12\n",
      "Epoch 9000, Loss: 3.4316877062651687e-12\n",
      "\n",
      "Final Predicted Output:\n",
      " [[0.49999882]\n",
      " [0.49999895]\n",
      " [0.50000071]\n",
      " [0.50000032]\n",
      " [0.50000255]\n",
      " [0.50000228]\n",
      " [0.50000098]\n",
      " [0.49999903]\n",
      " [0.49999845]\n",
      " [0.4999991 ]\n",
      " [0.50000478]\n",
      " [0.49999989]\n",
      " [0.50000019]\n",
      " [0.50000012]\n",
      " [0.50000218]\n",
      " [0.50000135]\n",
      " [0.49999897]\n",
      " [0.49999998]\n",
      " [0.49999818]\n",
      " [0.50000116]\n",
      " [0.50000255]\n",
      " [0.49999838]\n",
      " [0.50000054]\n",
      " [0.50000124]\n",
      " [0.50000036]\n",
      " [0.49999815]\n",
      " [0.50000265]\n",
      " [0.50000087]\n",
      " [0.50000073]\n",
      " [0.50000162]\n",
      " [0.50000063]\n",
      " [0.49999885]\n",
      " [0.49999972]\n",
      " [0.49999812]\n",
      " [0.49999309]\n",
      " [0.49999915]\n",
      " [0.49999934]\n",
      " [0.5000011 ]\n",
      " [0.50000006]\n",
      " [0.49999634]\n",
      " [0.49999983]\n",
      " [0.50000093]\n",
      " [0.5000023 ]\n",
      " [0.49999992]\n",
      " [0.50000091]\n",
      " [0.49999938]\n",
      " [0.50000022]\n",
      " [0.49999976]\n",
      " [0.50000259]\n",
      " [0.49999856]\n",
      " [0.50000102]\n",
      " [0.49999844]\n",
      " [0.49999789]\n",
      " [0.49999855]\n",
      " [0.50000025]\n",
      " [0.49999542]\n",
      " [0.5000013 ]\n",
      " [0.50000232]\n",
      " [0.50000062]\n",
      " [0.49999932]\n",
      " [0.50000063]\n",
      " [0.50000202]\n",
      " [0.50000277]\n",
      " [0.4999994 ]\n",
      " [0.49999868]\n",
      " [0.49999826]\n",
      " [0.49999824]\n",
      " [0.49999749]\n",
      " [0.50000019]\n",
      " [0.49999885]\n",
      " [0.49999936]\n",
      " [0.49999998]\n",
      " [0.49999888]\n",
      " [0.49999752]\n",
      " [0.50000051]\n",
      " [0.49999838]\n",
      " [0.50000177]\n",
      " [0.49999874]\n",
      " [0.50000005]\n",
      " [0.50000214]\n",
      " [0.49999838]\n",
      " [0.4999985 ]\n",
      " [0.49999997]\n",
      " [0.50000183]\n",
      " [0.49999948]\n",
      " [0.5000035 ]\n",
      " [0.49999876]\n",
      " [0.4999988 ]\n",
      " [0.50000062]\n",
      " [0.49999975]\n",
      " [0.50000088]\n",
      " [0.4999981 ]\n",
      " [0.49999724]\n",
      " [0.49999867]\n",
      " [0.4999999 ]\n",
      " [0.49999892]\n",
      " [0.49999571]\n",
      " [0.50000259]\n",
      " [0.5000011 ]\n",
      " [0.50000438]\n",
      " [0.50000038]\n",
      " [0.50000181]\n",
      " [0.50000089]\n",
      " [0.50000038]\n",
      " [0.50000164]\n",
      " [0.50000134]\n",
      " [0.50000333]\n",
      " [0.49999884]\n",
      " [0.50000045]\n",
      " [0.49999864]\n",
      " [0.50000088]\n",
      " [0.49999887]\n",
      " [0.49999689]\n",
      " [0.50000161]\n",
      " [0.50000121]\n",
      " [0.49999766]\n",
      " [0.49999821]\n",
      " [0.5000012 ]\n",
      " [0.49999917]\n",
      " [0.49999978]\n",
      " [0.50000039]\n",
      " [0.50000142]\n",
      " [0.50000254]\n",
      " [0.50000181]\n",
      " [0.50000111]\n",
      " [0.49999843]\n",
      " [0.50000075]\n",
      " [0.4999986 ]\n",
      " [0.50000297]\n",
      " [0.50000102]\n",
      " [0.49999999]\n",
      " [0.50000073]\n",
      " [0.49999991]\n",
      " [0.50000242]\n",
      " [0.49999722]\n",
      " [0.4999977 ]\n",
      " [0.50000016]\n",
      " [0.50000166]\n",
      " [0.50000196]\n",
      " [0.49999964]\n",
      " [0.50000066]\n",
      " [0.49999984]\n",
      " [0.49999971]\n",
      " [0.50000031]\n",
      " [0.50000167]\n",
      " [0.49999928]\n",
      " [0.50000056]\n",
      " [0.49999922]\n",
      " [0.50000354]\n",
      " [0.50000142]\n",
      " [0.50000454]\n",
      " [0.50000155]\n",
      " [0.50000291]\n",
      " [0.49999958]\n",
      " [0.49999664]\n",
      " [0.50000342]\n",
      " [0.49999875]\n",
      " [0.50000147]\n",
      " [0.50000075]\n",
      " [0.49999715]\n",
      " [0.50000211]\n",
      " [0.4999992 ]\n",
      " [0.49999941]\n",
      " [0.49999907]\n",
      " [0.50000189]\n",
      " [0.499999  ]\n",
      " [0.50000222]\n",
      " [0.50000071]\n",
      " [0.49999836]\n",
      " [0.5000002 ]\n",
      " [0.49999861]\n",
      " [0.50000012]\n",
      " [0.49999991]\n",
      " [0.49999877]\n",
      " [0.49999936]\n",
      " [0.50000251]\n",
      " [0.50000049]\n",
      " [0.50000006]\n",
      " [0.49999893]\n",
      " [0.50000041]\n",
      " [0.49999923]\n",
      " [0.50000205]\n",
      " [0.49999952]\n",
      " [0.49999938]\n",
      " [0.50000042]\n",
      " [0.50000109]\n",
      " [0.49999923]\n",
      " [0.49999837]\n",
      " [0.49999815]\n",
      " [0.50000192]\n",
      " [0.50000008]\n",
      " [0.49999581]\n",
      " [0.49999903]\n",
      " [0.50000214]\n",
      " [0.50000032]\n",
      " [0.50000038]\n",
      " [0.5000006 ]\n",
      " [0.49999747]\n",
      " [0.49999761]\n",
      " [0.4999975 ]\n",
      " [0.49999921]\n",
      " [0.50000162]\n",
      " [0.50000009]\n",
      " [0.50000018]\n",
      " [0.49999953]\n",
      " [0.50000064]\n",
      " [0.5000002 ]\n",
      " [0.49999926]\n",
      " [0.50000358]\n",
      " [0.50000055]\n",
      " [0.49999983]\n",
      " [0.50000214]\n",
      " [0.49999814]\n",
      " [0.50000005]\n",
      " [0.50000034]\n",
      " [0.49999875]\n",
      " [0.49999988]\n",
      " [0.49999687]\n",
      " [0.49999972]\n",
      " [0.49999956]\n",
      " [0.499999  ]\n",
      " [0.49999988]\n",
      " [0.50000507]\n",
      " [0.50000077]\n",
      " [0.50000078]\n",
      " [0.50000202]\n",
      " [0.49999612]\n",
      " [0.49999963]\n",
      " [0.50000013]\n",
      " [0.50000143]\n",
      " [0.49999967]\n",
      " [0.49999785]\n",
      " [0.49999994]\n",
      " [0.49999711]\n",
      " [0.50000017]\n",
      " [0.49999891]\n",
      " [0.50000415]\n",
      " [0.50000203]\n",
      " [0.50000079]\n",
      " [0.49999989]\n",
      " [0.49999807]\n",
      " [0.49999834]\n",
      " [0.49999975]\n",
      " [0.50000187]\n",
      " [0.50000207]\n",
      " [0.49999697]\n",
      " [0.50000109]\n",
      " [0.49999881]\n",
      " [0.49999896]\n",
      " [0.49999808]\n",
      " [0.50000253]\n",
      " [0.49999939]\n",
      " [0.49999811]\n",
      " [0.5000026 ]\n",
      " [0.50000045]\n",
      " [0.5000005 ]\n",
      " [0.4999991 ]\n",
      " [0.50000125]\n",
      " [0.49999955]\n",
      " [0.50000237]\n",
      " [0.50000159]\n",
      " [0.50000024]\n",
      " [0.50000328]\n",
      " [0.50000011]\n",
      " [0.49999807]\n",
      " [0.49999966]\n",
      " [0.4999964 ]\n",
      " [0.49999967]\n",
      " [0.50000355]\n",
      " [0.49999916]\n",
      " [0.50000003]\n",
      " [0.49999932]\n",
      " [0.49999908]\n",
      " [0.49999592]\n",
      " [0.49999688]\n",
      " [0.49999747]\n",
      " [0.49999858]\n",
      " [0.50000006]\n",
      " [0.49999686]\n",
      " [0.49999985]\n",
      " [0.50000044]\n",
      " [0.50000192]\n",
      " [0.50000169]\n",
      " [0.4999985 ]\n",
      " [0.50000125]\n",
      " [0.49999931]\n",
      " [0.49999993]\n",
      " [0.49999828]\n",
      " [0.49999995]\n",
      " [0.49999946]\n",
      " [0.50000121]\n",
      " [0.5000003 ]\n",
      " [0.50000116]\n",
      " [0.49999977]\n",
      " [0.50000071]\n",
      " [0.49999895]\n",
      " [0.49999655]\n",
      " [0.50000174]\n",
      " [0.49999933]\n",
      " [0.50000195]\n",
      " [0.49999879]\n",
      " [0.50000101]\n",
      " [0.50000018]\n",
      " [0.50000052]\n",
      " [0.49999892]\n",
      " [0.50000022]\n",
      " [0.49999869]\n",
      " [0.50000273]\n",
      " [0.49999846]\n",
      " [0.49999973]\n",
      " [0.49999691]\n",
      " [0.50000108]\n",
      " [0.49999981]\n",
      " [0.49999935]\n",
      " [0.49999705]\n",
      " [0.49999928]\n",
      " [0.50000328]\n",
      " [0.50000009]\n",
      " [0.50000186]\n",
      " [0.50000011]\n",
      " [0.49999956]\n",
      " [0.49999745]\n",
      " [0.49999988]\n",
      " [0.50000167]\n",
      " [0.49999845]\n",
      " [0.49999689]\n",
      " [0.49999928]\n",
      " [0.50000168]\n",
      " [0.49999878]\n",
      " [0.50000037]\n",
      " [0.49999854]\n",
      " [0.50000059]\n",
      " [0.50000023]\n",
      " [0.50000026]\n",
      " [0.50000146]\n",
      " [0.50000198]\n",
      " [0.49999864]\n",
      " [0.50000165]\n",
      " [0.49999861]\n",
      " [0.50000304]\n",
      " [0.50000247]\n",
      " [0.50000055]\n",
      " [0.50000117]\n",
      " [0.49999996]\n",
      " [0.50000142]\n",
      " [0.50000036]\n",
      " [0.49999506]\n",
      " [0.50000562]\n",
      " [0.50000232]\n",
      " [0.49999909]\n",
      " [0.50000488]\n",
      " [0.4999976 ]\n",
      " [0.4999967 ]\n",
      " [0.50000155]\n",
      " [0.49999989]\n",
      " [0.5000001 ]\n",
      " [0.50000131]\n",
      " [0.50000309]\n",
      " [0.49999743]\n",
      " [0.49999908]\n",
      " [0.50000042]\n",
      " [0.49999639]\n",
      " [0.50000061]\n",
      " [0.50000257]\n",
      " [0.49999724]\n",
      " [0.49999746]\n",
      " [0.49999783]\n",
      " [0.5000015 ]\n",
      " [0.50000102]\n",
      " [0.49999991]\n",
      " [0.50000091]\n",
      " [0.50000201]\n",
      " [0.50000278]\n",
      " [0.49999938]\n",
      " [0.49999896]\n",
      " [0.500001  ]\n",
      " [0.49999722]\n",
      " [0.50000208]\n",
      " [0.49999834]\n",
      " [0.49999858]\n",
      " [0.50000192]\n",
      " [0.49999866]\n",
      " [0.49999831]\n",
      " [0.49999796]\n",
      " [0.49999779]\n",
      " [0.49999691]\n",
      " [0.50000014]\n",
      " [0.50000192]\n",
      " [0.499999  ]\n",
      " [0.50000011]\n",
      " [0.49999806]\n",
      " [0.50000039]\n",
      " [0.49999878]\n",
      " [0.5000008 ]\n",
      " [0.49999894]\n",
      " [0.4999963 ]\n",
      " [0.49999962]\n",
      " [0.50000025]\n",
      " [0.49999883]\n",
      " [0.50000062]\n",
      " [0.50000196]\n",
      " [0.5000018 ]\n",
      " [0.49999707]\n",
      " [0.49999467]\n",
      " [0.5000015 ]\n",
      " [0.49999595]\n",
      " [0.49999948]\n",
      " [0.50000246]\n",
      " [0.49999845]\n",
      " [0.50000282]\n",
      " [0.49999905]\n",
      " [0.50000073]\n",
      " [0.49999551]\n",
      " [0.49999929]\n",
      " [0.50000012]\n",
      " [0.49999998]\n",
      " [0.49999787]\n",
      " [0.50000173]\n",
      " [0.49999701]\n",
      " [0.49999919]\n",
      " [0.49999868]\n",
      " [0.49999739]\n",
      " [0.49999959]\n",
      " [0.5000004 ]\n",
      " [0.50000319]\n",
      " [0.49999936]\n",
      " [0.49999722]\n",
      " [0.49999734]\n",
      " [0.49999857]\n",
      " [0.50000066]\n",
      " [0.50000395]\n",
      " [0.49999903]\n",
      " [0.49999716]\n",
      " [0.50000077]\n",
      " [0.50000058]\n",
      " [0.49999592]\n",
      " [0.50000311]\n",
      " [0.4999996 ]\n",
      " [0.4999975 ]\n",
      " [0.49999952]\n",
      " [0.50000333]\n",
      " [0.49999624]\n",
      " [0.49999884]\n",
      " [0.50000042]\n",
      " [0.5000008 ]\n",
      " [0.49999633]\n",
      " [0.50000026]\n",
      " [0.49999904]\n",
      " [0.50000114]\n",
      " [0.49999857]\n",
      " [0.50000035]\n",
      " [0.50000173]\n",
      " [0.50000138]\n",
      " [0.49999808]\n",
      " [0.49999839]\n",
      " [0.50000123]\n",
      " [0.4999993 ]\n",
      " [0.49999973]\n",
      " [0.49999939]\n",
      " [0.5000004 ]\n",
      " [0.50000447]\n",
      " [0.49999903]\n",
      " [0.50000028]\n",
      " [0.49999911]\n",
      " [0.50000081]\n",
      " [0.50000003]\n",
      " [0.50000232]\n",
      " [0.49999934]\n",
      " [0.49999962]\n",
      " [0.49999515]\n",
      " [0.50000271]\n",
      " [0.50000034]\n",
      " [0.50000338]\n",
      " [0.49999982]\n",
      " [0.4999983 ]\n",
      " [0.49999767]\n",
      " [0.49999766]\n",
      " [0.50000102]\n",
      " [0.4999984 ]\n",
      " [0.50000096]\n",
      " [0.50000171]\n",
      " [0.49999969]\n",
      " [0.50000176]\n",
      " [0.4999994 ]\n",
      " [0.50000057]\n",
      " [0.50000197]\n",
      " [0.50000193]\n",
      " [0.49999957]\n",
      " [0.50000038]\n",
      " [0.49999842]\n",
      " [0.49999812]\n",
      " [0.49999657]\n",
      " [0.50000057]\n",
      " [0.49999949]\n",
      " [0.50000118]\n",
      " [0.50000311]\n",
      " [0.49999838]\n",
      " [0.50000278]\n",
      " [0.4999994 ]\n",
      " [0.4999976 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv(\"student_dataset.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df.drop(columns=[\"Final_Score\"]).values  # All columns except target\n",
    "y = df[\"Final_Score\"].values.reshape(-1, 1)  # Target column\n",
    "\n",
    "# Normalize features\n",
    "X = X / np.amax(X, axis=0)\n",
    "y = y / 100  # Normalize target\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Weights initialization\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    \n",
    "    def sigmoid_derivative(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1)\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2)\n",
    "        self.output = self.sigmoid(self.z2)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        output_error = y - self.output  # Error in output\n",
    "        output_delta = output_error * self.sigmoid_derivative(self.output)  # Applying derivative of sigmoid\n",
    "        \n",
    "        hidden_error = output_delta.dot(self.W2.T)  # Error in hidden layer\n",
    "        hidden_delta = hidden_error * self.sigmoid_derivative(self.a1)  # Applying derivative of sigmoid\n",
    "        \n",
    "        # Weight updates\n",
    "        self.W2 += self.a1.T.dot(output_delta) * self.learning_rate\n",
    "        self.W1 += X.T.dot(hidden_delta) * self.learning_rate\n",
    "    \n",
    "    def train(self, X, y, epochs=10000):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(X, y)\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = np.mean(np.square(y - self.output))\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Initialize and train the neural network\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 8  # You can adjust this\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "NN = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)\n",
    "print(\"Initial Loss:\", np.mean(np.square(y - NN.forward(X))))\n",
    "\n",
    "NN.train(X, y)\n",
    "\n",
    "print(\"\\nFinal Predicted Output:\\n\", NN.forward(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a012c5f-451b-488a-a2e4-00df3c48e65d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\jupyter\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0059  \n",
      "Epoch 2/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 \n",
      "Epoch 3/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0041e-04 \n",
      "Epoch 4/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7473e-04 \n",
      "Epoch 5/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3630e-04 \n",
      "Epoch 6/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4164e-04 \n",
      "Epoch 7/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6204e-04 \n",
      "Epoch 8/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1926e-04 \n",
      "Epoch 9/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0715e-04 \n",
      "Epoch 10/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9620e-04 \n",
      "Epoch 11/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9305e-04 \n",
      "Epoch 12/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7007e-04 \n",
      "Epoch 13/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6663e-04 \n",
      "Epoch 14/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5199e-04 \n",
      "Epoch 15/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3681e-04 \n",
      "Epoch 16/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3172e-04 \n",
      "Epoch 17/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2220e-04 \n",
      "Epoch 18/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2395e-04 \n",
      "Epoch 19/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1308e-04 \n",
      "Epoch 20/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9164e-04 \n",
      "Epoch 21/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8446e-04 \n",
      "Epoch 22/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7869e-04 \n",
      "Epoch 23/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6803e-04 \n",
      "Epoch 24/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8743e-04 \n",
      "Epoch 25/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6114e-04 \n",
      "Epoch 26/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5002e-04 \n",
      "Epoch 27/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4432e-04 \n",
      "Epoch 28/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3565e-04 \n",
      "Epoch 29/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3601e-04 \n",
      "Epoch 30/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1636e-04 \n",
      "Epoch 31/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3037e-04 \n",
      "Epoch 32/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1508e-04 \n",
      "Epoch 33/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0345e-04 \n",
      "Epoch 34/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0587e-04 \n",
      "Epoch 35/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3501e-05 \n",
      "Epoch 36/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4561e-05 \n",
      "Epoch 37/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5178e-05 \n",
      "Epoch 38/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4096e-05 \n",
      "Epoch 39/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3028e-05 \n",
      "Epoch 40/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6765e-05 \n",
      "Epoch 41/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3790e-05 \n",
      "Epoch 42/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6003e-05 \n",
      "Epoch 43/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0102e-05 \n",
      "Epoch 44/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1588e-05 \n",
      "Epoch 45/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8598e-05 \n",
      "Epoch 46/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9534e-05 \n",
      "Epoch 47/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0208e-05 \n",
      "Epoch 48/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6246e-05 \n",
      "Epoch 49/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2758e-05 \n",
      "Epoch 50/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9167e-05 \n",
      "Epoch 51/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3825e-05 \n",
      "Epoch 52/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3243e-05 \n",
      "Epoch 53/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2962e-05 \n",
      "Epoch 54/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7212e-05 \n",
      "Epoch 55/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9460e-05 \n",
      "Epoch 56/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4908e-05 \n",
      "Epoch 57/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3778e-05 \n",
      "Epoch 58/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9814e-05 \n",
      "Epoch 59/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1912e-05 \n",
      "Epoch 60/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8516e-05 \n",
      "Epoch 61/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9973e-05 \n",
      "Epoch 62/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8185e-05 \n",
      "Epoch 63/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7283e-05 \n",
      "Epoch 64/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7282e-05 \n",
      "Epoch 65/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3302e-05 \n",
      "Epoch 66/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4356e-05 \n",
      "Epoch 67/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3068e-05 \n",
      "Epoch 68/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2927e-05 \n",
      "Epoch 69/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1085e-05 \n",
      "Epoch 70/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9198e-05 \n",
      "Epoch 71/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9638e-05 \n",
      "Epoch 72/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8693e-05 \n",
      "Epoch 73/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7083e-05 \n",
      "Epoch 74/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8308e-05 \n",
      "Epoch 75/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8357e-05 \n",
      "Epoch 76/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7202e-05 \n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6639e-05 \n",
      "Epoch 78/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4692e-05 \n",
      "Epoch 79/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4916e-05 \n",
      "Epoch 80/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5060e-05 \n",
      "Epoch 81/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3668e-05 \n",
      "Epoch 82/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3838e-05 \n",
      "Epoch 83/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3136e-05 \n",
      "Epoch 84/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2842e-05 \n",
      "Epoch 85/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3355e-05 \n",
      "Epoch 86/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2046e-05 \n",
      "Epoch 87/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1604e-05 \n",
      "Epoch 88/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0775e-05 \n",
      "Epoch 89/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1269e-05 \n",
      "Epoch 90/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0590e-05 \n",
      "Epoch 91/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0408e-05 \n",
      "Epoch 92/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0034e-05 \n",
      "Epoch 93/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6880e-06 \n",
      "Epoch 94/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6453e-06 \n",
      "Epoch 95/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7037e-06 \n",
      "Epoch 96/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9505e-06 \n",
      "Epoch 97/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0739e-06 \n",
      "Epoch 98/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6870e-06 \n",
      "Epoch 99/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2768e-06 \n",
      "Epoch 100/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1467e-06 \n",
      "Epoch 101/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7159e-06 \n",
      "Epoch 102/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5595e-06 \n",
      "Epoch 103/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0847e-06 \n",
      "Epoch 104/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9311e-06 \n",
      "Epoch 105/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4798e-06 \n",
      "Epoch 106/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4647e-06 \n",
      "Epoch 107/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4373e-06 \n",
      "Epoch 108/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1401e-06 \n",
      "Epoch 109/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8835e-06 \n",
      "Epoch 110/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0749e-06 \n",
      "Epoch 111/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6706e-06 \n",
      "Epoch 112/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4941e-06 \n",
      "Epoch 113/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1682e-06 \n",
      "Epoch 114/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7134e-06 \n",
      "Epoch 115/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0737e-06 \n",
      "Epoch 116/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8218e-06 \n",
      "Epoch 117/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6520e-06 \n",
      "Epoch 118/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3208e-06 \n",
      "Epoch 119/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6242e-06 \n",
      "Epoch 120/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2556e-06 \n",
      "Epoch 121/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3229e-06 \n",
      "Epoch 122/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9723e-06 \n",
      "Epoch 123/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2195e-06 \n",
      "Epoch 124/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0079e-06 \n",
      "Epoch 125/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6942e-06 \n",
      "Epoch 126/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4335e-06 \n",
      "Epoch 127/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5541e-06 \n",
      "Epoch 128/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9014e-06 \n",
      "Epoch 129/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0916e-06 \n",
      "Epoch 130/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2972e-06 \n",
      "Epoch 131/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1820e-06 \n",
      "Epoch 132/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8916e-06 \n",
      "Epoch 133/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1696e-06 \n",
      "Epoch 134/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8537e-06 \n",
      "Epoch 135/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6638e-06 \n",
      "Epoch 136/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6100e-06 \n",
      "Epoch 137/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4944e-06 \n",
      "Epoch 138/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5505e-06 \n",
      "Epoch 139/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2565e-06 \n",
      "Epoch 140/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4715e-06 \n",
      "Epoch 141/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3842e-06 \n",
      "Epoch 142/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5331e-06 \n",
      "Epoch 143/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2725e-06 \n",
      "Epoch 144/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1917e-06 \n",
      "Epoch 145/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1368e-06 \n",
      "Epoch 146/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8419e-06 \n",
      "Epoch 147/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0808e-06 \n",
      "Epoch 148/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9374e-06 \n",
      "Epoch 149/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9535e-06 \n",
      "Epoch 150/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7629e-06 \n",
      "Epoch 151/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7645e-06 \n",
      "Epoch 152/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8605e-06 \n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4385e-06 \n",
      "Epoch 154/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6964e-06 \n",
      "Epoch 155/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5824e-06 \n",
      "Epoch 156/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4833e-06 \n",
      "Epoch 157/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5022e-06 \n",
      "Epoch 158/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4415e-06 \n",
      "Epoch 159/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2870e-06 \n",
      "Epoch 160/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4704e-06 \n",
      "Epoch 161/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3907e-06 \n",
      "Epoch 162/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3400e-06 \n",
      "Epoch 163/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3954e-06 \n",
      "Epoch 164/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2711e-06 \n",
      "Epoch 165/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2652e-06 \n",
      "Epoch 166/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3328e-06 \n",
      "Epoch 167/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2210e-06 \n",
      "Epoch 168/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4168e-06 \n",
      "Epoch 169/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1684e-06 \n",
      "Epoch 170/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1997e-06 \n",
      "Epoch 171/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1330e-06 \n",
      "Epoch 172/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0845e-06 \n",
      "Epoch 173/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1025e-06 \n",
      "Epoch 174/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1423e-06 \n",
      "Epoch 175/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1114e-06 \n",
      "Epoch 176/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0220e-06 \n",
      "Epoch 177/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0606e-06 \n",
      "Epoch 178/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0650e-06 \n",
      "Epoch 179/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0616e-06 \n",
      "Epoch 180/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8184e-07 \n",
      "Epoch 181/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5757e-07 \n",
      "Epoch 182/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0124e-06 \n",
      "Epoch 183/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8862e-07 \n",
      "Epoch 184/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9313e-07 \n",
      "Epoch 185/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6875e-07 \n",
      "Epoch 186/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6717e-07 \n",
      "Epoch 187/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6949e-07 \n",
      "Epoch 188/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9018e-07 \n",
      "Epoch 189/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2553e-07 \n",
      "Epoch 190/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6316e-07 \n",
      "Epoch 191/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4328e-07 \n",
      "Epoch 192/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7554e-07 \n",
      "Epoch 193/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9017e-07 \n",
      "Epoch 194/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3860e-07 \n",
      "Epoch 195/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0062e-06 \n",
      "Epoch 196/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0125e-07 \n",
      "Epoch 197/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9353e-07 \n",
      "Epoch 198/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9802e-07 \n",
      "Epoch 199/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7651e-07 \n",
      "Epoch 200/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6390e-07 \n",
      "Epoch 201/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9690e-07 \n",
      "Epoch 202/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0910e-07 \n",
      "Epoch 203/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1623e-07 \n",
      "Epoch 204/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3025e-07 \n",
      "Epoch 205/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4363e-07 \n",
      "Epoch 206/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8379e-07 \n",
      "Epoch 207/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9779e-07 \n",
      "Epoch 208/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8583e-07 \n",
      "Epoch 209/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7152e-07 \n",
      "Epoch 210/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5550e-07 \n",
      "Epoch 211/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8687e-07 \n",
      "Epoch 212/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6435e-07 \n",
      "Epoch 213/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2563e-07 \n",
      "Epoch 214/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0709e-07 \n",
      "Epoch 215/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9369e-07 \n",
      "Epoch 216/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8006e-07 \n",
      "Epoch 217/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7627e-07 \n",
      "Epoch 218/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0789e-07 \n",
      "Epoch 219/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3582e-07 \n",
      "Epoch 220/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3337e-07 \n",
      "Epoch 221/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5800e-07 \n",
      "Epoch 222/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3958e-07 \n",
      "Epoch 223/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9546e-07 \n",
      "Epoch 224/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9317e-07 \n",
      "Epoch 225/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2447e-07 \n",
      "Epoch 226/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0449e-07 \n",
      "Epoch 227/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9674e-07 \n",
      "Epoch 228/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6473e-07 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7054e-07 \n",
      "Epoch 230/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6493e-07 \n",
      "Epoch 231/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5919e-07 \n",
      "Epoch 232/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4692e-07 \n",
      "Epoch 233/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8705e-07 \n",
      "Epoch 234/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6597e-07 \n",
      "Epoch 235/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4852e-07 \n",
      "Epoch 236/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9776e-07 \n",
      "Epoch 237/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4823e-07 \n",
      "Epoch 238/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8521e-07 \n",
      "Epoch 239/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1687e-07 \n",
      "Epoch 240/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7059e-07 \n",
      "Epoch 241/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3361e-07 \n",
      "Epoch 242/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0705e-07 \n",
      "Epoch 243/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8127e-07 \n",
      "Epoch 244/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6673e-07 \n",
      "Epoch 245/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6211e-07 \n",
      "Epoch 246/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9716e-07 \n",
      "Epoch 247/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4655e-07 \n",
      "Epoch 248/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2957e-07 \n",
      "Epoch 249/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6435e-07 \n",
      "Epoch 250/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0056e-07 \n",
      "Epoch 251/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7726e-07 \n",
      "Epoch 252/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8049e-07 \n",
      "Epoch 253/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0525e-07 \n",
      "Epoch 254/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5361e-07 \n",
      "Epoch 255/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7069e-07 \n",
      "Epoch 256/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1618e-07 \n",
      "Epoch 257/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7322e-07 \n",
      "Epoch 258/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6226e-07 \n",
      "Epoch 259/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6399e-07 \n",
      "Epoch 260/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7671e-07 \n",
      "Epoch 261/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6128e-07 \n",
      "Epoch 262/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6369e-07 \n",
      "Epoch 263/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0964e-07 \n",
      "Epoch 264/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8288e-07 \n",
      "Epoch 265/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1732e-07 \n",
      "Epoch 266/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7579e-07 \n",
      "Epoch 267/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2161e-07 \n",
      "Epoch 268/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9037e-07 \n",
      "Epoch 269/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5876e-07 \n",
      "Epoch 270/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0735e-07 \n",
      "Epoch 271/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4239e-07 \n",
      "Epoch 272/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1068e-07 \n",
      "Epoch 273/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1097e-07 \n",
      "Epoch 274/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0143e-07 \n",
      "Epoch 275/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4872e-07 \n",
      "Epoch 276/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8572e-07 \n",
      "Epoch 277/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8417e-07 \n",
      "Epoch 278/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9850e-07 \n",
      "Epoch 279/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9979e-07 \n",
      "Epoch 280/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0098e-07 \n",
      "Epoch 281/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1465e-07 \n",
      "Epoch 282/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8846e-07 \n",
      "Epoch 283/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0092e-07 \n",
      "Epoch 284/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5848e-07 \n",
      "Epoch 285/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6629e-07 \n",
      "Epoch 286/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9249e-07 \n",
      "Epoch 287/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1212e-07 \n",
      "Epoch 288/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2051e-07 \n",
      "Epoch 289/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1782e-07 \n",
      "Epoch 290/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4337e-07 \n",
      "Epoch 291/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7485e-07 \n",
      "Epoch 292/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7345e-07 \n",
      "Epoch 293/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6206e-07 \n",
      "Epoch 294/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9317e-07 \n",
      "Epoch 295/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2973e-07 \n",
      "Epoch 296/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0558e-07 \n",
      "Epoch 297/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6721e-07 \n",
      "Epoch 298/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9859e-07 \n",
      "Epoch 299/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7111e-07 \n",
      "Epoch 300/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3933e-07 \n",
      "Epoch 301/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2140e-07 \n",
      "Epoch 302/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8348e-07 \n",
      "Epoch 303/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2280e-07 \n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8364e-07 \n",
      "Epoch 305/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8497e-07 \n",
      "Epoch 306/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0424e-07 \n",
      "Epoch 307/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5577e-07 \n",
      "Epoch 308/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8899e-07 \n",
      "Epoch 309/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1251e-07 \n",
      "Epoch 310/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6735e-07 \n",
      "Epoch 311/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8839e-07 \n",
      "Epoch 312/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3529e-07 \n",
      "Epoch 313/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0932e-07 \n",
      "Epoch 314/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9302e-07 \n",
      "Epoch 315/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2439e-07 \n",
      "Epoch 316/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8794e-07 \n",
      "Epoch 317/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5562e-07 \n",
      "Epoch 318/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0828e-07 \n",
      "Epoch 319/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9108e-07 \n",
      "Epoch 320/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4784e-07 \n",
      "Epoch 321/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6009e-07 \n",
      "Epoch 322/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1211e-07 \n",
      "Epoch 323/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1671e-07 \n",
      "Epoch 324/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0458e-07 \n",
      "Epoch 325/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0993e-07 \n",
      "Epoch 326/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7755e-07 \n",
      "Epoch 327/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0811e-07 \n",
      "Epoch 328/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4818e-07 \n",
      "Epoch 329/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3160e-07 \n",
      "Epoch 330/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6055e-07 \n",
      "Epoch 331/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0513e-07 \n",
      "Epoch 332/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2402e-07 \n",
      "Epoch 333/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1922e-07 \n",
      "Epoch 334/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0633e-07 \n",
      "Epoch 335/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2856e-07 \n",
      "Epoch 336/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3381e-07 \n",
      "Epoch 337/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6527e-07 \n",
      "Epoch 338/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9841e-07 \n",
      "Epoch 339/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9722e-07 \n",
      "Epoch 340/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5211e-07 \n",
      "Epoch 341/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6543e-07 \n",
      "Epoch 342/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9234e-07 \n",
      "Epoch 343/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3800e-07 \n",
      "Epoch 344/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7311e-07 \n",
      "Epoch 345/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8480e-07 \n",
      "Epoch 346/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1364e-07 \n",
      "Epoch 347/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4594e-07 \n",
      "Epoch 348/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1000e-07 \n",
      "Epoch 349/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6034e-07 \n",
      "Epoch 350/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7409e-07 \n",
      "Epoch 351/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2189e-07 \n",
      "Epoch 352/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6941e-07 \n",
      "Epoch 353/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8946e-07 \n",
      "Epoch 354/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7354e-07 \n",
      "Epoch 355/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9331e-07 \n",
      "Epoch 356/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8510e-07 \n",
      "Epoch 357/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9028e-07 \n",
      "Epoch 358/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6180e-07 \n",
      "Epoch 359/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8826e-07 \n",
      "Epoch 360/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8722e-07 \n",
      "Epoch 361/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0147e-07 \n",
      "Epoch 362/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4655e-07 \n",
      "Epoch 363/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7211e-07 \n",
      "Epoch 364/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2246e-07 \n",
      "Epoch 365/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1084e-07 \n",
      "Epoch 366/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9235e-07 \n",
      "Epoch 367/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6027e-07 \n",
      "Epoch 368/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4755e-07 \n",
      "Epoch 369/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0373e-07 \n",
      "Epoch 370/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9026e-07 \n",
      "Epoch 371/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8115e-07 \n",
      "Epoch 372/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5763e-07 \n",
      "Epoch 373/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4374e-07 \n",
      "Epoch 374/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4401e-07 \n",
      "Epoch 375/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5101e-07 \n",
      "Epoch 376/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9777e-07 \n",
      "Epoch 377/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0625e-07 \n",
      "Epoch 378/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9737e-07 \n",
      "Epoch 379/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4864e-07 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3369e-07 \n",
      "Epoch 381/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0183e-07 \n",
      "Epoch 382/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2043e-07 \n",
      "Epoch 383/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4238e-07 \n",
      "Epoch 384/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6630e-07 \n",
      "Epoch 385/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5352e-07 \n",
      "Epoch 386/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3940e-07 \n",
      "Epoch 387/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5971e-07 \n",
      "Epoch 388/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4241e-07 \n",
      "Epoch 389/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8659e-07 \n",
      "Epoch 390/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4556e-07 \n",
      "Epoch 391/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9389e-07 \n",
      "Epoch 392/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4294e-07 \n",
      "Epoch 393/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0227e-07 \n",
      "Epoch 394/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3130e-07 \n",
      "Epoch 395/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0293e-07 \n",
      "Epoch 396/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1810e-07 \n",
      "Epoch 397/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4613e-07 \n",
      "Epoch 398/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0333e-07 \n",
      "Epoch 399/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5669e-07 \n",
      "Epoch 400/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7934e-07 \n",
      "Epoch 401/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5032e-07 \n",
      "Epoch 402/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5157e-07 \n",
      "Epoch 403/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4881e-07 \n",
      "Epoch 404/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2985e-07 \n",
      "Epoch 405/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0308e-07 \n",
      "Epoch 406/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6080e-07 \n",
      "Epoch 407/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6573e-07 \n",
      "Epoch 408/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1241e-07 \n",
      "Epoch 409/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1079e-07 \n",
      "Epoch 410/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0202e-07 \n",
      "Epoch 411/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4315e-07 \n",
      "Epoch 412/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8861e-07 \n",
      "Epoch 413/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7205e-07 \n",
      "Epoch 414/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6365e-07 \n",
      "Epoch 415/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0659e-07 \n",
      "Epoch 416/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8624e-07 \n",
      "Epoch 417/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3080e-07 \n",
      "Epoch 418/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8230e-07 \n",
      "Epoch 419/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4731e-07 \n",
      "Epoch 420/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0458e-07 \n",
      "Epoch 421/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2891e-07 \n",
      "Epoch 422/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7145e-07 \n",
      "Epoch 423/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3977e-07 \n",
      "Epoch 424/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5444e-07 \n",
      "Epoch 425/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8096e-07 \n",
      "Epoch 426/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6930e-07 \n",
      "Epoch 427/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5554e-07 \n",
      "Epoch 428/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6699e-07 \n",
      "Epoch 429/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0291e-07 \n",
      "Epoch 430/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7595e-07 \n",
      "Epoch 431/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1324e-07 \n",
      "Epoch 432/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5491e-07 \n",
      "Epoch 433/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5108e-07 \n",
      "Epoch 434/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5760e-07 \n",
      "Epoch 435/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0884e-07 \n",
      "Epoch 436/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5185e-07 \n",
      "Epoch 437/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8297e-07 \n",
      "Epoch 438/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6844e-07 \n",
      "Epoch 439/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3024e-07 \n",
      "Epoch 440/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8161e-07 \n",
      "Epoch 441/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0101e-07 \n",
      "Epoch 442/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4326e-07 \n",
      "Epoch 443/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4631e-07 \n",
      "Epoch 444/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4972e-07 \n",
      "Epoch 445/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4974e-07 \n",
      "Epoch 446/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5861e-07 \n",
      "Epoch 447/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4548e-07 \n",
      "Epoch 448/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3045e-07 \n",
      "Epoch 449/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1141e-07 \n",
      "Epoch 450/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0533e-07 \n",
      "Epoch 451/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9000e-07 \n",
      "Epoch 452/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4107e-07 \n",
      "Epoch 453/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1341e-07 \n",
      "Epoch 454/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0851e-07 \n",
      "Epoch 455/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3861e-07 \n",
      "Epoch 456/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9805e-07 \n",
      "Epoch 457/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9792e-07 \n",
      "Epoch 458/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9853e-07 \n",
      "Epoch 459/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9148e-07 \n",
      "Epoch 460/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9218e-07 \n",
      "Epoch 461/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9654e-07 \n",
      "Epoch 462/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4850e-07 \n",
      "Epoch 463/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1480e-07 \n",
      "Epoch 464/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0667e-07 \n",
      "Epoch 465/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2283e-07 \n",
      "Epoch 466/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1367e-07 \n",
      "Epoch 467/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9908e-07 \n",
      "Epoch 468/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9090e-07 \n",
      "Epoch 469/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8625e-07 \n",
      "Epoch 470/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0339e-07 \n",
      "Epoch 471/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5497e-07 \n",
      "Epoch 472/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6429e-07 \n",
      "Epoch 473/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8274e-07 \n",
      "Epoch 474/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6625e-07 \n",
      "Epoch 475/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8190e-07 \n",
      "Epoch 476/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7290e-07 \n",
      "Epoch 477/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9922e-07 \n",
      "Epoch 478/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3824e-07 \n",
      "Epoch 479/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7214e-07 \n",
      "Epoch 480/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8529e-07 \n",
      "Epoch 481/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2921e-07 \n",
      "Epoch 482/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5181e-07 \n",
      "Epoch 483/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0660e-07 \n",
      "Epoch 484/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2125e-07 \n",
      "Epoch 485/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3025e-07 \n",
      "Epoch 486/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2810e-07 \n",
      "Epoch 487/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9728e-07 \n",
      "Epoch 488/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6785e-07 \n",
      "Epoch 489/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3771e-07 \n",
      "Epoch 490/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6176e-07 \n",
      "Epoch 491/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0753e-07 \n",
      "Epoch 492/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2045e-07 \n",
      "Epoch 493/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8548e-07 \n",
      "Epoch 494/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9475e-07 \n",
      "Epoch 495/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0544e-07 \n",
      "Epoch 496/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6680e-07 \n",
      "Epoch 497/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8207e-07 \n",
      "Epoch 498/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0041e-07 \n",
      "Epoch 499/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8408e-07 \n",
      "Epoch 500/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6293e-07 \n",
      "Epoch 501/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9725e-07 \n",
      "Epoch 502/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6514e-07 \n",
      "Epoch 503/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4855e-07 \n",
      "Epoch 504/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3200e-07 \n",
      "Epoch 505/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8810e-07 \n",
      "Epoch 506/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7626e-07 \n",
      "Epoch 507/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7732e-07 \n",
      "Epoch 508/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3831e-07 \n",
      "Epoch 509/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7233e-07 \n",
      "Epoch 510/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6512e-07 \n",
      "Epoch 511/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8260e-07 \n",
      "Epoch 512/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7751e-07 \n",
      "Epoch 513/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9334e-07 \n",
      "Epoch 514/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4546e-07 \n",
      "Epoch 515/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4719e-07 \n",
      "Epoch 516/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6034e-07 \n",
      "Epoch 517/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7334e-07 \n",
      "Epoch 518/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9593e-07 \n",
      "Epoch 519/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4849e-07 \n",
      "Epoch 520/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6859e-07 \n",
      "Epoch 521/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1123e-07 \n",
      "Epoch 522/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6192e-07 \n",
      "Epoch 523/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9040e-07 \n",
      "Epoch 524/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2014e-07 \n",
      "Epoch 525/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3586e-07 \n",
      "Epoch 526/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6293e-07 \n",
      "Epoch 527/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3333e-07 \n",
      "Epoch 528/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0088e-07 \n",
      "Epoch 529/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4649e-07 \n",
      "Epoch 530/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7391e-07 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2140e-07 \n",
      "Epoch 532/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8634e-07 \n",
      "Epoch 533/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4866e-07 \n",
      "Epoch 534/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4850e-07 \n",
      "Epoch 535/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4260e-07 \n",
      "Epoch 536/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5914e-07 \n",
      "Epoch 537/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6592e-07 \n",
      "Epoch 538/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4915e-07 \n",
      "Epoch 539/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7207e-07 \n",
      "Epoch 540/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1682e-07 \n",
      "Epoch 541/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4364e-07 \n",
      "Epoch 542/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2659e-07 \n",
      "Epoch 543/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5648e-07 \n",
      "Epoch 544/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4346e-07 \n",
      "Epoch 545/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5003e-07 \n",
      "Epoch 546/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6730e-07 \n",
      "Epoch 547/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5035e-07 \n",
      "Epoch 548/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7730e-07 \n",
      "Epoch 549/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6959e-07 \n",
      "Epoch 550/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6843e-07 \n",
      "Epoch 551/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7008e-07 \n",
      "Epoch 552/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8400e-07 \n",
      "Epoch 553/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6206e-07 \n",
      "Epoch 554/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7145e-07 \n",
      "Epoch 555/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3326e-07 \n",
      "Epoch 556/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1126e-07 \n",
      "Epoch 557/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3967e-07 \n",
      "Epoch 558/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3304e-07 \n",
      "Epoch 559/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6633e-07 \n",
      "Epoch 560/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9398e-07 \n",
      "Epoch 561/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2679e-07 \n",
      "Epoch 562/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4361e-07 \n",
      "Epoch 563/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5616e-07 \n",
      "Epoch 564/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2315e-07 \n",
      "Epoch 565/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4619e-07 \n",
      "Epoch 566/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3828e-07 \n",
      "Epoch 567/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2836e-07 \n",
      "Epoch 568/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2191e-07 \n",
      "Epoch 569/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4597e-07 \n",
      "Epoch 570/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1496e-07 \n",
      "Epoch 571/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3689e-07 \n",
      "Epoch 572/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1839e-07 \n",
      "Epoch 573/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8863e-07 \n",
      "Epoch 574/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3661e-07 \n",
      "Epoch 575/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7460e-07 \n",
      "Epoch 576/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8541e-07 \n",
      "Epoch 577/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3826e-07 \n",
      "Epoch 578/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9930e-07 \n",
      "Epoch 579/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2660e-07 \n",
      "Epoch 580/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0963e-07 \n",
      "Epoch 581/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5862e-08 \n",
      "Epoch 582/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7764e-07 \n",
      "Epoch 583/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2047e-07 \n",
      "Epoch 584/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1614e-07 \n",
      "Epoch 585/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1206e-07 \n",
      "Epoch 586/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0824e-07 \n",
      "Epoch 587/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2273e-07 \n",
      "Epoch 588/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3617e-07 \n",
      "Epoch 589/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3721e-07 \n",
      "Epoch 590/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2251e-07 \n",
      "Epoch 591/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9849e-07 \n",
      "Epoch 592/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5125e-07 \n",
      "Epoch 593/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8135e-08 \n",
      "Epoch 594/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0804e-07 \n",
      "Epoch 595/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2172e-07 \n",
      "Epoch 596/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5832e-08 \n",
      "Epoch 597/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8686e-07 \n",
      "Epoch 598/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9320e-07 \n",
      "Epoch 599/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5570e-07 \n",
      "Epoch 600/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4546e-08 \n",
      "Epoch 601/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0558e-07 \n",
      "Epoch 602/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0478e-07 \n",
      "Epoch 603/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2913e-07 \n",
      "Epoch 604/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0920e-07 \n",
      "Epoch 605/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8184e-07 \n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8753e-08 \n",
      "Epoch 607/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7925e-08 \n",
      "Epoch 608/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9377e-08 \n",
      "Epoch 609/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2346e-07 \n",
      "Epoch 610/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3291e-07 \n",
      "Epoch 611/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4594e-07 \n",
      "Epoch 612/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3778e-07 \n",
      "Epoch 613/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4952e-07 \n",
      "Epoch 614/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5985e-07 \n",
      "Epoch 615/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4659e-07 \n",
      "Epoch 616/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3146e-07 \n",
      "Epoch 617/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6299e-07 \n",
      "Epoch 618/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7736e-08 \n",
      "Epoch 619/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2126e-08 \n",
      "Epoch 620/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0335e-07 \n",
      "Epoch 621/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0855e-07 \n",
      "Epoch 622/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6492e-08 \n",
      "Epoch 623/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2920e-07 \n",
      "Epoch 624/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0238e-07 \n",
      "Epoch 625/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4892e-08 \n",
      "Epoch 626/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1077e-07 \n",
      "Epoch 627/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1504e-07 \n",
      "Epoch 628/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1160e-07 \n",
      "Epoch 629/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1155e-07 \n",
      "Epoch 630/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1984e-07 \n",
      "Epoch 631/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1882e-07 \n",
      "Epoch 632/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7608e-08 \n",
      "Epoch 633/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2227e-07 \n",
      "Epoch 634/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6139e-07 \n",
      "Epoch 635/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9703e-08 \n",
      "Epoch 636/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7954e-08 \n",
      "Epoch 637/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0825e-07 \n",
      "Epoch 638/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3330e-07 \n",
      "Epoch 639/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0636e-07 \n",
      "Epoch 640/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9314e-08 \n",
      "Epoch 641/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4527e-08 \n",
      "Epoch 642/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3177e-07 \n",
      "Epoch 643/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2219e-08 \n",
      "Epoch 644/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6528e-07 \n",
      "Epoch 645/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1136e-08 \n",
      "Epoch 646/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1550e-07 \n",
      "Epoch 647/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8108e-07 \n",
      "Epoch 648/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3337e-07 \n",
      "Epoch 649/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0911e-07 \n",
      "Epoch 650/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4530e-08 \n",
      "Epoch 651/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3850e-08 \n",
      "Epoch 652/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5139e-07 \n",
      "Epoch 653/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8491e-08 \n",
      "Epoch 654/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1823e-07 \n",
      "Epoch 655/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7323e-07 \n",
      "Epoch 656/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0631e-07 \n",
      "Epoch 657/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1151e-08 \n",
      "Epoch 658/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1650e-07 \n",
      "Epoch 659/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0815e-08 \n",
      "Epoch 660/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2722e-07 \n",
      "Epoch 661/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7800e-07 \n",
      "Epoch 662/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2751e-07 \n",
      "Epoch 663/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7515e-08 \n",
      "Epoch 664/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2094e-07 \n",
      "Epoch 665/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8441e-08 \n",
      "Epoch 666/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0268e-07 \n",
      "Epoch 667/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3194e-08 \n",
      "Epoch 668/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6564e-07 \n",
      "Epoch 669/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6669e-08 \n",
      "Epoch 670/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7643e-08 \n",
      "Epoch 671/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2417e-08 \n",
      "Epoch 672/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0049e-08 \n",
      "Epoch 673/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4842e-08 \n",
      "Epoch 674/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5984e-07 \n",
      "Epoch 675/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1376e-07 \n",
      "Epoch 676/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2868e-08 \n",
      "Epoch 677/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1166e-07 \n",
      "Epoch 678/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0744e-07 \n",
      "Epoch 679/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7236e-07 \n",
      "Epoch 680/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0678e-08 \n",
      "Epoch 681/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0102e-07 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6978e-08 \n",
      "Epoch 683/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1054e-07 \n",
      "Epoch 684/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3107e-08 \n",
      "Epoch 685/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2397e-08 \n",
      "Epoch 686/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0383e-07 \n",
      "Epoch 687/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0177e-08 \n",
      "Epoch 688/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7469e-08 \n",
      "Epoch 689/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1978e-07 \n",
      "Epoch 690/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7736e-08 \n",
      "Epoch 691/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8078e-08 \n",
      "Epoch 692/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1940e-07 \n",
      "Epoch 693/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3520e-08 \n",
      "Epoch 694/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5741e-08 \n",
      "Epoch 695/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9974e-08 \n",
      "Epoch 696/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1085e-07 \n",
      "Epoch 697/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2287e-08 \n",
      "Epoch 698/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7390e-08 \n",
      "Epoch 699/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0016e-08 \n",
      "Epoch 700/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7219e-08 \n",
      "Epoch 701/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2542e-08 \n",
      "Epoch 702/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9936e-08 \n",
      "Epoch 703/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9991e-08 \n",
      "Epoch 704/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3553e-08 \n",
      "Epoch 705/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0937e-08 \n",
      "Epoch 706/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5835e-08 \n",
      "Epoch 707/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0809e-08 \n",
      "Epoch 708/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0574e-07 \n",
      "Epoch 709/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3847e-08 \n",
      "Epoch 710/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0405e-07 \n",
      "Epoch 711/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0654e-08 \n",
      "Epoch 712/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4357e-08 \n",
      "Epoch 713/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4854e-08 \n",
      "Epoch 714/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3017e-08 \n",
      "Epoch 715/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2125e-08 \n",
      "Epoch 716/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4168e-08 \n",
      "Epoch 717/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0415e-07\n",
      "Epoch 718/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9357e-07 \n",
      "Epoch 719/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8730e-08 \n",
      "Epoch 720/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1474e-07 \n",
      "Epoch 721/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3237e-07 \n",
      "Epoch 722/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6256e-07 \n",
      "Epoch 723/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8106e-08 \n",
      "Epoch 724/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1071e-07 \n",
      "Epoch 725/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4094e-07 \n",
      "Epoch 726/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7417e-08 \n",
      "Epoch 727/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4646e-08 \n",
      "Epoch 728/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3369e-07 \n",
      "Epoch 729/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3805e-08 \n",
      "Epoch 730/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9388e-08 \n",
      "Epoch 731/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6292e-08 \n",
      "Epoch 732/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2311e-07 \n",
      "Epoch 733/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8126e-08 \n",
      "Epoch 734/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4024e-07 \n",
      "Epoch 735/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1750e-07 \n",
      "Epoch 736/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8116e-08 \n",
      "Epoch 737/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1518e-07 \n",
      "Epoch 738/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2771e-08 \n",
      "Epoch 739/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2794e-08 \n",
      "Epoch 740/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5798e-08 \n",
      "Epoch 741/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3588e-08 \n",
      "Epoch 742/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4254e-08 \n",
      "Epoch 743/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1950e-08 \n",
      "Epoch 744/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1261e-08 \n",
      "Epoch 745/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6782e-08 \n",
      "Epoch 746/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6741e-08 \n",
      "Epoch 747/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8243e-08 \n",
      "Epoch 748/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3992e-08 \n",
      "Epoch 749/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5500e-08 \n",
      "Epoch 750/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7753e-08 \n",
      "Epoch 751/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2515e-08 \n",
      "Epoch 752/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0254e-08 \n",
      "Epoch 753/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5828e-08 \n",
      "Epoch 754/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7541e-08 \n",
      "Epoch 755/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4763e-08 \n",
      "Epoch 756/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6401e-07 \n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1296e-07 \n",
      "Epoch 758/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4795e-08 \n",
      "Epoch 759/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9098e-07 \n",
      "Epoch 760/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1409e-08 \n",
      "Epoch 761/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0840e-08 \n",
      "Epoch 762/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7206e-08 \n",
      "Epoch 763/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2137e-08 \n",
      "Epoch 764/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3196e-08 \n",
      "Epoch 765/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3964e-08 \n",
      "Epoch 766/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3362e-08 \n",
      "Epoch 767/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2687e-08 \n",
      "Epoch 768/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8387e-08 \n",
      "Epoch 769/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2157e-08 \n",
      "Epoch 770/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6934e-08 \n",
      "Epoch 771/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5812e-08 \n",
      "Epoch 772/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6274e-08 \n",
      "Epoch 773/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2373e-08 \n",
      "Epoch 774/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1118e-07 \n",
      "Epoch 775/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6186e-08 \n",
      "Epoch 776/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6175e-08 \n",
      "Epoch 777/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4245e-08 \n",
      "Epoch 778/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9381e-08 \n",
      "Epoch 779/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0061e-08 \n",
      "Epoch 780/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3824e-08 \n",
      "Epoch 781/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2971e-07 \n",
      "Epoch 782/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1521e-07 \n",
      "Epoch 783/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2368e-08 \n",
      "Epoch 784/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7423e-08 \n",
      "Epoch 785/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6081e-08 \n",
      "Epoch 786/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7389e-08 \n",
      "Epoch 787/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1876e-08 \n",
      "Epoch 788/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5434e-08 \n",
      "Epoch 789/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6329e-08 \n",
      "Epoch 790/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7650e-08 \n",
      "Epoch 791/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4008e-08 \n",
      "Epoch 792/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1147e-08 \n",
      "Epoch 793/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1011e-07 \n",
      "Epoch 794/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0240e-07 \n",
      "Epoch 795/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1736e-08 \n",
      "Epoch 796/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8731e-08 \n",
      "Epoch 797/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4288e-07 \n",
      "Epoch 798/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7687e-08 \n",
      "Epoch 799/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8405e-08 \n",
      "Epoch 800/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7897e-08 \n",
      "Epoch 801/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2978e-08 \n",
      "Epoch 802/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8185e-08 \n",
      "Epoch 803/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7901e-08 \n",
      "Epoch 804/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7064e-08 \n",
      "Epoch 805/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0597e-08 \n",
      "Epoch 806/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1508e-08 \n",
      "Epoch 807/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6508e-08 \n",
      "Epoch 808/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5469e-08 \n",
      "Epoch 809/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8959e-08 \n",
      "Epoch 810/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1742e-08 \n",
      "Epoch 811/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2613e-07 \n",
      "Epoch 812/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6485e-08 \n",
      "Epoch 813/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8559e-08 \n",
      "Epoch 814/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2141e-07 \n",
      "Epoch 815/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8018e-08 \n",
      "Epoch 816/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2141e-08 \n",
      "Epoch 817/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1635e-08 \n",
      "Epoch 818/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3789e-08 \n",
      "Epoch 819/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2265e-08 \n",
      "Epoch 820/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6567e-08 \n",
      "Epoch 821/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4547e-08 \n",
      "Epoch 822/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5042e-08 \n",
      "Epoch 823/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3271e-08 \n",
      "Epoch 824/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5078e-08 \n",
      "Epoch 825/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6309e-08 \n",
      "Epoch 826/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6746e-08 \n",
      "Epoch 827/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0220e-08 \n",
      "Epoch 828/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4712e-08 \n",
      "Epoch 829/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3773e-07 \n",
      "Epoch 830/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3414e-07 \n",
      "Epoch 831/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3895e-07 \n",
      "Epoch 832/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4560e-08 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0155e-08 \n",
      "Epoch 834/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2945e-08 \n",
      "Epoch 835/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6491e-08 \n",
      "Epoch 836/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7899e-08 \n",
      "Epoch 837/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8198e-08 \n",
      "Epoch 838/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1725e-08 \n",
      "Epoch 839/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0336e-08 \n",
      "Epoch 840/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5291e-08 \n",
      "Epoch 841/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9701e-08 \n",
      "Epoch 842/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6655e-08 \n",
      "Epoch 843/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0119e-08 \n",
      "Epoch 844/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1218e-08 \n",
      "Epoch 845/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2124e-08 \n",
      "Epoch 846/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4039e-08 \n",
      "Epoch 847/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1277e-07 \n",
      "Epoch 848/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3027e-07 \n",
      "Epoch 849/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1799e-08 \n",
      "Epoch 850/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0121e-08 \n",
      "Epoch 851/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7627e-08 \n",
      "Epoch 852/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3788e-08 \n",
      "Epoch 853/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1438e-08 \n",
      "Epoch 854/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4830e-08 \n",
      "Epoch 855/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8895e-08 \n",
      "Epoch 856/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0885e-08 \n",
      "Epoch 857/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0748e-08 \n",
      "Epoch 858/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1369e-08 \n",
      "Epoch 859/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1224e-08 \n",
      "Epoch 860/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7066e-08 \n",
      "Epoch 861/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1611e-08 \n",
      "Epoch 862/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9664e-08 \n",
      "Epoch 863/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1232e-08 \n",
      "Epoch 864/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8043e-08 \n",
      "Epoch 865/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2546e-08 \n",
      "Epoch 866/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8360e-08 \n",
      "Epoch 867/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7462e-08 \n",
      "Epoch 868/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2499e-08 \n",
      "Epoch 869/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4175e-08 \n",
      "Epoch 870/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6076e-08 \n",
      "Epoch 871/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6328e-08 \n",
      "Epoch 872/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8844e-08 \n",
      "Epoch 873/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7882e-08 \n",
      "Epoch 874/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7875e-08 \n",
      "Epoch 875/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8011e-08 \n",
      "Epoch 876/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2128e-08 \n",
      "Epoch 877/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5298e-08 \n",
      "Epoch 878/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1623e-08 \n",
      "Epoch 879/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2096e-08 \n",
      "Epoch 880/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8005e-08 \n",
      "Epoch 881/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3801e-08 \n",
      "Epoch 882/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6552e-08 \n",
      "Epoch 883/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4207e-08 \n",
      "Epoch 884/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8310e-08 \n",
      "Epoch 885/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0757e-07 \n",
      "Epoch 886/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4286e-07 \n",
      "Epoch 887/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9332e-08 \n",
      "Epoch 888/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7555e-08 \n",
      "Epoch 889/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7481e-08 \n",
      "Epoch 890/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9662e-08 \n",
      "Epoch 891/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6757e-08 \n",
      "Epoch 892/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4213e-08 \n",
      "Epoch 893/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3051e-08 \n",
      "Epoch 894/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8181e-08 \n",
      "Epoch 895/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4482e-08 \n",
      "Epoch 896/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7385e-08 \n",
      "Epoch 897/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2255e-08 \n",
      "Epoch 898/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6706e-08 \n",
      "Epoch 899/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3657e-08 \n",
      "Epoch 900/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1620e-08 \n",
      "Epoch 901/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3491e-08 \n",
      "Epoch 902/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1862e-08 \n",
      "Epoch 903/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1932e-08 \n",
      "Epoch 904/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9787e-08 \n",
      "Epoch 905/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5768e-08 \n",
      "Epoch 906/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4350e-08 \n",
      "Epoch 907/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6646e-08 \n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0752e-07 \n",
      "Epoch 909/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4533e-08 \n",
      "Epoch 910/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2267e-08 \n",
      "Epoch 911/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1750e-08 \n",
      "Epoch 912/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2265e-08 \n",
      "Epoch 913/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9238e-08 \n",
      "Epoch 914/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9587e-08 \n",
      "Epoch 915/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6927e-08 \n",
      "Epoch 916/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1224e-08 \n",
      "Epoch 917/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9660e-08 \n",
      "Epoch 918/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3800e-08 \n",
      "Epoch 919/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8565e-08 \n",
      "Epoch 920/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7289e-08 \n",
      "Epoch 921/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0772e-08 \n",
      "Epoch 922/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5476e-08 \n",
      "Epoch 923/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6208e-08 \n",
      "Epoch 924/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0788e-08 \n",
      "Epoch 925/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5610e-08 \n",
      "Epoch 926/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7737e-08 \n",
      "Epoch 927/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1861e-08 \n",
      "Epoch 928/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8686e-08 \n",
      "Epoch 929/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0757e-08 \n",
      "Epoch 930/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5080e-08 \n",
      "Epoch 931/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0290e-08 \n",
      "Epoch 932/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7367e-08 \n",
      "Epoch 933/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9598e-08 \n",
      "Epoch 934/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2788e-08 \n",
      "Epoch 935/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1403e-08 \n",
      "Epoch 936/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3982e-08 \n",
      "Epoch 937/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6077e-08 \n",
      "Epoch 938/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2470e-08 \n",
      "Epoch 939/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3523e-08 \n",
      "Epoch 940/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7001e-08 \n",
      "Epoch 941/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9953e-08 \n",
      "Epoch 942/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4920e-08 \n",
      "Epoch 943/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6778e-08 \n",
      "Epoch 944/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1474e-08 \n",
      "Epoch 945/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4770e-08 \n",
      "Epoch 946/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1610e-08 \n",
      "Epoch 947/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7877e-08 \n",
      "Epoch 948/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4915e-08 \n",
      "Epoch 949/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1591e-07 \n",
      "Epoch 950/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0000e-07 \n",
      "Epoch 951/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9862e-08 \n",
      "Epoch 952/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8203e-08 \n",
      "Epoch 953/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1864e-08 \n",
      "Epoch 954/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8046e-08 \n",
      "Epoch 955/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7844e-08 \n",
      "Epoch 956/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8584e-08 \n",
      "Epoch 957/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9356e-08 \n",
      "Epoch 958/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2707e-08 \n",
      "Epoch 959/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3655e-08 \n",
      "Epoch 960/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7204e-08 \n",
      "Epoch 961/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4908e-08 \n",
      "Epoch 962/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7675e-08 \n",
      "Epoch 963/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1637e-08 \n",
      "Epoch 964/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5878e-08 \n",
      "Epoch 965/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4034e-08 \n",
      "Epoch 966/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6702e-08 \n",
      "Epoch 967/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5010e-08 \n",
      "Epoch 968/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9478e-08 \n",
      "Epoch 969/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4883e-08 \n",
      "Epoch 970/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2270e-08 \n",
      "Epoch 971/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1957e-08 \n",
      "Epoch 972/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2575e-08 \n",
      "Epoch 973/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8903e-08 \n",
      "Epoch 974/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1370e-08 \n",
      "Epoch 975/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0520e-08 \n",
      "Epoch 976/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6819e-08 \n",
      "Epoch 977/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4723e-08 \n",
      "Epoch 978/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1397e-08 \n",
      "Epoch 979/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0671e-07 \n",
      "Epoch 980/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6839e-08 \n",
      "Epoch 981/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9931e-08 \n",
      "Epoch 982/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8000e-08 \n",
      "Epoch 983/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3966e-08 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3878e-08 \n",
      "Epoch 985/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9411e-08 \n",
      "Epoch 986/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8533e-08 \n",
      "Epoch 987/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2531e-08 \n",
      "Epoch 988/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5264e-08 \n",
      "Epoch 989/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2796e-08 \n",
      "Epoch 990/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9165e-08 \n",
      "Epoch 991/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3242e-08 \n",
      "Epoch 992/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3377e-08 \n",
      "Epoch 993/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5498e-08 \n",
      "Epoch 994/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7157e-08 \n",
      "Epoch 995/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4254e-08 \n",
      "Epoch 996/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9556e-08 \n",
      "Epoch 997/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9743e-08 \n",
      "Epoch 998/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5370e-08 \n",
      "Epoch 999/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5315e-08 \n",
      "Epoch 1000/1000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9870e-08 \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "Final Predicted Output:\n",
      " [[0.5001462 ]\n",
      " [0.5005506 ]\n",
      " [0.5001848 ]\n",
      " [0.5002675 ]\n",
      " [0.50026554]\n",
      " [0.50033855]\n",
      " [0.5000597 ]\n",
      " [0.50023615]\n",
      " [0.50052565]\n",
      " [0.500188  ]\n",
      " [0.49993378]\n",
      " [0.50005007]\n",
      " [0.50002337]\n",
      " [0.49981382]\n",
      " [0.50005263]\n",
      " [0.5001228 ]\n",
      " [0.4998391 ]\n",
      " [0.49999902]\n",
      " [0.5003166 ]\n",
      " [0.5004368 ]\n",
      " [0.4999333 ]\n",
      " [0.5001912 ]\n",
      " [0.5000571 ]\n",
      " [0.5003431 ]\n",
      " [0.5001216 ]\n",
      " [0.50030446]\n",
      " [0.50018466]\n",
      " [0.50013435]\n",
      " [0.49982902]\n",
      " [0.50039625]\n",
      " [0.5001403 ]\n",
      " [0.50020105]\n",
      " [0.50015867]\n",
      " [0.5002487 ]\n",
      " [0.50014985]\n",
      " [0.50020397]\n",
      " [0.49967352]\n",
      " [0.5004889 ]\n",
      " [0.5002538 ]\n",
      " [0.500249  ]\n",
      " [0.5001581 ]\n",
      " [0.5000444 ]\n",
      " [0.50021064]\n",
      " [0.5000574 ]\n",
      " [0.49978912]\n",
      " [0.5000895 ]\n",
      " [0.49993855]\n",
      " [0.49973938]\n",
      " [0.4999389 ]\n",
      " [0.4998666 ]\n",
      " [0.5000688 ]\n",
      " [0.49990988]\n",
      " [0.5003059 ]\n",
      " [0.50016004]\n",
      " [0.500227  ]\n",
      " [0.49983692]\n",
      " [0.50009805]\n",
      " [0.5002028 ]\n",
      " [0.50000113]\n",
      " [0.5002245 ]\n",
      " [0.5002784 ]\n",
      " [0.49937388]\n",
      " [0.5002521 ]\n",
      " [0.50007033]\n",
      " [0.5000855 ]\n",
      " [0.5002171 ]\n",
      " [0.5002708 ]\n",
      " [0.49996507]\n",
      " [0.49994072]\n",
      " [0.50016487]\n",
      " [0.50025964]\n",
      " [0.5003004 ]\n",
      " [0.50012916]\n",
      " [0.5001687 ]\n",
      " [0.5001849 ]\n",
      " [0.50026745]\n",
      " [0.5000367 ]\n",
      " [0.5001161 ]\n",
      " [0.49991634]\n",
      " [0.50015557]\n",
      " [0.5003233 ]\n",
      " [0.49998298]\n",
      " [0.5003381 ]\n",
      " [0.50022036]\n",
      " [0.5001398 ]\n",
      " [0.5001558 ]\n",
      " [0.49950498]\n",
      " [0.50021976]\n",
      " [0.5002588 ]\n",
      " [0.50001514]\n",
      " [0.49992856]\n",
      " [0.49971646]\n",
      " [0.5000978 ]\n",
      " [0.50007653]\n",
      " [0.5001129 ]\n",
      " [0.50020003]\n",
      " [0.500229  ]\n",
      " [0.500136  ]\n",
      " [0.50017446]\n",
      " [0.5000218 ]\n",
      " [0.5001569 ]\n",
      " [0.5001961 ]\n",
      " [0.5000739 ]\n",
      " [0.50011086]\n",
      " [0.50038004]\n",
      " [0.5001823 ]\n",
      " [0.4999791 ]\n",
      " [0.49977928]\n",
      " [0.49970368]\n",
      " [0.500474  ]\n",
      " [0.5001114 ]\n",
      " [0.50014025]\n",
      " [0.50017107]\n",
      " [0.50013983]\n",
      " [0.5001242 ]\n",
      " [0.49989223]\n",
      " [0.50022393]\n",
      " [0.49992105]\n",
      " [0.5001335 ]\n",
      " [0.5004143 ]\n",
      " [0.49984732]\n",
      " [0.49992326]\n",
      " [0.4999969 ]\n",
      " [0.50014126]\n",
      " [0.5001501 ]\n",
      " [0.50031155]\n",
      " [0.50012016]\n",
      " [0.50032485]\n",
      " [0.5000273 ]\n",
      " [0.5002965 ]\n",
      " [0.5000781 ]\n",
      " [0.50004387]\n",
      " [0.5000305 ]\n",
      " [0.49996367]\n",
      " [0.50017035]\n",
      " [0.5003394 ]\n",
      " [0.5002024 ]\n",
      " [0.500221  ]\n",
      " [0.50041735]\n",
      " [0.5000776 ]\n",
      " [0.49995202]\n",
      " [0.50013137]\n",
      " [0.50001645]\n",
      " [0.49993324]\n",
      " [0.4996644 ]\n",
      " [0.49991557]\n",
      " [0.50001895]\n",
      " [0.50030327]\n",
      " [0.49999434]\n",
      " [0.50020456]\n",
      " [0.49954706]\n",
      " [0.50012445]\n",
      " [0.5000794 ]\n",
      " [0.5001955 ]\n",
      " [0.50027126]\n",
      " [0.5000607 ]\n",
      " [0.5001091 ]\n",
      " [0.500161  ]\n",
      " [0.5001049 ]\n",
      " [0.50026035]\n",
      " [0.5002208 ]\n",
      " [0.5001584 ]\n",
      " [0.5001402 ]\n",
      " [0.50014055]\n",
      " [0.5002742 ]\n",
      " [0.5001755 ]\n",
      " [0.5001568 ]\n",
      " [0.50011444]\n",
      " [0.500082  ]\n",
      " [0.49980098]\n",
      " [0.49962327]\n",
      " [0.50040156]\n",
      " [0.4999871 ]\n",
      " [0.5002167 ]\n",
      " [0.5002445 ]\n",
      " [0.4997357 ]\n",
      " [0.50009537]\n",
      " [0.50039136]\n",
      " [0.5001695 ]\n",
      " [0.49999574]\n",
      " [0.50027573]\n",
      " [0.5002027 ]\n",
      " [0.5000815 ]\n",
      " [0.4998653 ]\n",
      " [0.50017464]\n",
      " [0.49996284]\n",
      " [0.5000272 ]\n",
      " [0.4999571 ]\n",
      " [0.5001767 ]\n",
      " [0.5001768 ]\n",
      " [0.5000659 ]\n",
      " [0.5002792 ]\n",
      " [0.50031745]\n",
      " [0.49963075]\n",
      " [0.5000161 ]\n",
      " [0.50003326]\n",
      " [0.5002395 ]\n",
      " [0.50036913]\n",
      " [0.5003022 ]\n",
      " [0.5002885 ]\n",
      " [0.5003054 ]\n",
      " [0.50010574]\n",
      " [0.5001118 ]\n",
      " [0.5001532 ]\n",
      " [0.5000857 ]\n",
      " [0.50023866]\n",
      " [0.5001615 ]\n",
      " [0.50017345]\n",
      " [0.5001807 ]\n",
      " [0.499944  ]\n",
      " [0.5001651 ]\n",
      " [0.50004697]\n",
      " [0.5002753 ]\n",
      " [0.4998121 ]\n",
      " [0.5001763 ]\n",
      " [0.50004256]\n",
      " [0.50020236]\n",
      " [0.49957553]\n",
      " [0.4998653 ]\n",
      " [0.5002653 ]\n",
      " [0.5002489 ]\n",
      " [0.49966297]\n",
      " [0.4997825 ]\n",
      " [0.50011843]\n",
      " [0.50012136]\n",
      " [0.4998398 ]\n",
      " [0.500041  ]\n",
      " [0.50003004]\n",
      " [0.5001893 ]\n",
      " [0.5001669 ]\n",
      " [0.50030833]\n",
      " [0.50024796]\n",
      " [0.5000529 ]\n",
      " [0.5001455 ]\n",
      " [0.50013894]\n",
      " [0.50006086]\n",
      " [0.4999486 ]\n",
      " [0.5002101 ]\n",
      " [0.5001868 ]\n",
      " [0.50023854]\n",
      " [0.5006422 ]\n",
      " [0.5002431 ]\n",
      " [0.50014114]\n",
      " [0.5001626 ]\n",
      " [0.5001073 ]\n",
      " [0.5002451 ]\n",
      " [0.50023127]\n",
      " [0.5004566 ]\n",
      " [0.50026536]\n",
      " [0.5002272 ]\n",
      " [0.4999122 ]\n",
      " [0.5001693 ]\n",
      " [0.5002625 ]\n",
      " [0.4996695 ]\n",
      " [0.50035346]\n",
      " [0.49980703]\n",
      " [0.50001955]\n",
      " [0.4996222 ]\n",
      " [0.50019324]\n",
      " [0.50029516]\n",
      " [0.5000137 ]\n",
      " [0.49983606]\n",
      " [0.5001807 ]\n",
      " [0.5002807 ]\n",
      " [0.5003066 ]\n",
      " [0.50031877]\n",
      " [0.500264  ]\n",
      " [0.5000945 ]\n",
      " [0.50011224]\n",
      " [0.49988288]\n",
      " [0.49990278]\n",
      " [0.4997834 ]\n",
      " [0.5000963 ]\n",
      " [0.49982396]\n",
      " [0.50011027]\n",
      " [0.49985737]\n",
      " [0.49974105]\n",
      " [0.5004915 ]\n",
      " [0.5003493 ]\n",
      " [0.5001427 ]\n",
      " [0.5003629 ]\n",
      " [0.5001164 ]\n",
      " [0.50014716]\n",
      " [0.5001527 ]\n",
      " [0.5002835 ]\n",
      " [0.50001186]\n",
      " [0.49997458]\n",
      " [0.50034165]\n",
      " [0.50018203]\n",
      " [0.5000738 ]\n",
      " [0.50014985]\n",
      " [0.50001514]\n",
      " [0.50048876]\n",
      " [0.5003128 ]\n",
      " [0.5001317 ]\n",
      " [0.5002412 ]\n",
      " [0.5003077 ]\n",
      " [0.50017595]\n",
      " [0.50014997]\n",
      " [0.49983904]\n",
      " [0.49986607]\n",
      " [0.49994287]\n",
      " [0.50005615]\n",
      " [0.500127  ]\n",
      " [0.5002275 ]\n",
      " [0.5000707 ]\n",
      " [0.50025094]\n",
      " [0.49974665]\n",
      " [0.5004104 ]\n",
      " [0.5001824 ]\n",
      " [0.50008416]\n",
      " [0.5003351 ]\n",
      " [0.5002794 ]\n",
      " [0.5001682 ]\n",
      " [0.49992594]\n",
      " [0.5000702 ]\n",
      " [0.5001144 ]\n",
      " [0.5002321 ]\n",
      " [0.5001477 ]\n",
      " [0.49996173]\n",
      " [0.5001606 ]\n",
      " [0.50023067]\n",
      " [0.5001394 ]\n",
      " [0.50011164]\n",
      " [0.5000728 ]\n",
      " [0.5001184 ]\n",
      " [0.5002923 ]\n",
      " [0.500123  ]\n",
      " [0.50005496]\n",
      " [0.50018334]\n",
      " [0.50021243]\n",
      " [0.5002606 ]\n",
      " [0.50028247]\n",
      " [0.49987364]\n",
      " [0.5002347 ]\n",
      " [0.50020653]\n",
      " [0.5000222 ]\n",
      " [0.5000949 ]\n",
      " [0.5001415 ]\n",
      " [0.5002856 ]\n",
      " [0.50020695]\n",
      " [0.5001147 ]\n",
      " [0.50029624]\n",
      " [0.49995148]\n",
      " [0.5001178 ]\n",
      " [0.5001548 ]\n",
      " [0.5000781 ]\n",
      " [0.49999157]\n",
      " [0.49982324]\n",
      " [0.50020015]\n",
      " [0.4998425 ]\n",
      " [0.50008154]\n",
      " [0.5001313 ]\n",
      " [0.4998382 ]\n",
      " [0.50016   ]\n",
      " [0.50021523]\n",
      " [0.49999762]\n",
      " [0.5000325 ]\n",
      " [0.49972832]\n",
      " [0.50004053]\n",
      " [0.50017834]\n",
      " [0.5000417 ]\n",
      " [0.50021863]\n",
      " [0.50019145]\n",
      " [0.5001019 ]\n",
      " [0.5001737 ]\n",
      " [0.50034976]\n",
      " [0.5000882 ]\n",
      " [0.50007975]\n",
      " [0.49996313]\n",
      " [0.5002002 ]\n",
      " [0.50012   ]\n",
      " [0.50029826]\n",
      " [0.4998503 ]\n",
      " [0.5003426 ]\n",
      " [0.5001586 ]\n",
      " [0.5001788 ]\n",
      " [0.49989164]\n",
      " [0.5001962 ]\n",
      " [0.50013125]\n",
      " [0.5001588 ]\n",
      " [0.500489  ]\n",
      " [0.50013685]\n",
      " [0.5002219 ]\n",
      " [0.5000828 ]\n",
      " [0.50007236]\n",
      " [0.50033283]\n",
      " [0.5004144 ]\n",
      " [0.5002425 ]\n",
      " [0.50031126]\n",
      " [0.50072056]\n",
      " [0.5000553 ]\n",
      " [0.5001841 ]\n",
      " [0.5001087 ]\n",
      " [0.50004816]\n",
      " [0.50013864]\n",
      " [0.5004162 ]\n",
      " [0.5001906 ]\n",
      " [0.5001359 ]\n",
      " [0.50023854]\n",
      " [0.50007004]\n",
      " [0.50027233]\n",
      " [0.49992278]\n",
      " [0.50022864]\n",
      " [0.5000138 ]\n",
      " [0.49962172]\n",
      " [0.5001044 ]\n",
      " [0.50006735]\n",
      " [0.5001583 ]\n",
      " [0.49994156]\n",
      " [0.4999548 ]\n",
      " [0.5001067 ]\n",
      " [0.50011516]\n",
      " [0.50015056]\n",
      " [0.50041044]\n",
      " [0.5004636 ]\n",
      " [0.5001512 ]\n",
      " [0.49984378]\n",
      " [0.5000428 ]\n",
      " [0.500271  ]\n",
      " [0.5001948 ]\n",
      " [0.500342  ]\n",
      " [0.5002751 ]\n",
      " [0.5000423 ]\n",
      " [0.500242  ]\n",
      " [0.5002568 ]\n",
      " [0.49993357]\n",
      " [0.50025916]\n",
      " [0.50038683]\n",
      " [0.50014627]\n",
      " [0.5003178 ]\n",
      " [0.5000862 ]\n",
      " [0.50018156]\n",
      " [0.500227  ]\n",
      " [0.50035375]\n",
      " [0.5003222 ]\n",
      " [0.50008357]\n",
      " [0.5000843 ]\n",
      " [0.50001293]\n",
      " [0.5002294 ]\n",
      " [0.50013506]\n",
      " [0.50018024]\n",
      " [0.5002252 ]\n",
      " [0.5001575 ]\n",
      " [0.49998435]\n",
      " [0.50001264]\n",
      " [0.50022733]\n",
      " [0.49991515]\n",
      " [0.5004885 ]\n",
      " [0.50028944]\n",
      " [0.50019264]\n",
      " [0.500171  ]\n",
      " [0.5001364 ]\n",
      " [0.50026983]\n",
      " [0.50029325]\n",
      " [0.50000346]\n",
      " [0.5006156 ]\n",
      " [0.49984962]\n",
      " [0.50040233]\n",
      " [0.4999958 ]\n",
      " [0.5000691 ]\n",
      " [0.49995467]\n",
      " [0.50013167]\n",
      " [0.50032103]\n",
      " [0.49973172]\n",
      " [0.50014323]\n",
      " [0.5001872 ]\n",
      " [0.49996528]\n",
      " [0.50026596]\n",
      " [0.49998772]\n",
      " [0.5001911 ]\n",
      " [0.50001967]\n",
      " [0.5003429 ]\n",
      " [0.49992874]\n",
      " [0.49976733]\n",
      " [0.50043845]\n",
      " [0.5001894 ]\n",
      " [0.5003494 ]\n",
      " [0.5005399 ]\n",
      " [0.50003386]\n",
      " [0.50016546]\n",
      " [0.5001607 ]\n",
      " [0.50023246]\n",
      " [0.4996229 ]\n",
      " [0.50021094]\n",
      " [0.5002464 ]\n",
      " [0.500083  ]\n",
      " [0.50009835]\n",
      " [0.50015545]\n",
      " [0.49994758]\n",
      " [0.5000813 ]\n",
      " [0.4999629 ]\n",
      " [0.50029993]\n",
      " [0.5001311 ]\n",
      " [0.49997666]\n",
      " [0.5003829 ]\n",
      " [0.5002098 ]\n",
      " [0.5001342 ]\n",
      " [0.50009257]\n",
      " [0.50031555]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv(\"student_dataset.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df.drop(columns=[\"Final_Score\"]).values  # All columns except target\n",
    "y = df[\"Final_Score\"].values.reshape(-1, 1)  # Target column\n",
    "\n",
    "# Normalize features\n",
    "X = X / np.amax(X, axis=0)\n",
    "y = y / 100  # Normalize target\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(8, activation='sigmoid', input_shape=(X.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=1000, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = model.predict(X)\n",
    "print(\"\\nFinal Predicted Output:\\n\", predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1c2df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13772\\3337975950.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# DO NOT EDIT. Generated by api_gen.sh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDTypePolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFloatDTypePolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInitializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\api\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\api\\activations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\activations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\saving\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_registration\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_registration\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_keras_serializable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialization_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialization_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\saving\\saving_api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlegacy_h5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfile_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\models\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialization\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlegacy_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_build_map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\models\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_mapping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmap_saveable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbase_trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraceback_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\trainers\\trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCompileLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCompileMetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraceback_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribution_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_data_adapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_dataset_adapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_adapter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataAdapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_slicing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpandas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnp_version_under1p19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# numpy versioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from pandas.util._decorators import (  # noqa:F401\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\jupyter\\lib\\site-packages\\pandas\\_libs\\interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv(\"student_dataset.csv\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df.drop(columns=[\"Final_Score\"]).values  # All columns except target\n",
    "y = df[\"Final_Score\"].values.reshape(-1, 1)  # Target column\n",
    "\n",
    "# Normalize features\n",
    "X = X / np.amax(X, axis=0)\n",
    "y = y / 100  # Normalize target\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(8, activation='sigmoid', input_shape=(X.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=1000, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "predicted_output = model.predict(X)\n",
    "print(\"\\nFinal Predicted Output:\\n\", predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
